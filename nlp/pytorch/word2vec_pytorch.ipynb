{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from nltk.corpus import brown\n",
    "from  gensim.utils import simple_preprocess\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_words = brown.words()\n",
    "brown_text = \" \".join(brown.words()).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sentences: 57340\n"
     ]
    }
   ],
   "source": [
    "num_sents = len(brown.sents())\n",
    "print(\"number of sentences:\", num_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41239"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(simple_preprocess(brown_text.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'y']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {\"x\":4, \"y\":3}\n",
    "list(a.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Word2VecModel, self).__init__()\n",
    "        self.target_embeddings = nn.Embedding(vocab_size, embedding_dim, sparse=True)\n",
    "        self.context_embeddings = nn.Embedding(vocab_size, embedding_dim, sparse=True)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.target_embeddings.weight.data.uniform_(-1, 1)\n",
    "        self.context_embeddings.weight.data.uniform_(-1, 1)\n",
    "\n",
    "    def forward(self, target_words, context_words, negative_words):\n",
    "        target_embeds = self.target_embeddings(target_words)\n",
    "        context_embeds = self.context_embeddings(context_words)\n",
    "        negative_embeds = self.context_embeddings(negative_words)\n",
    "\n",
    "        positive_score = torch.sum(target_embeds * context_embeds, dim=1)\n",
    "        negative_score = torch.bmm(negative_embeds, target_embeds.unsqueeze(2)).squeeze()\n",
    "\n",
    "        return -torch.mean(torch.log(torch.sigmoid(positive_score)) + torch.sum(torch.log(torch.sigmoid(-negative_score)), dim=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_brown_corpus():\n",
    "    processed_sentences = []\n",
    "    for sentence in brown.sents():\n",
    "        processed_sentence = simple_preprocess(' '.join(sentence), deacc=True)  \n",
    "        processed_sentences.append(processed_sentence)\n",
    "    return processed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset():\n",
    "    # Example corpus\n",
    "    corpus = preprocess_brown_corpus()\n",
    "    print(\"preprocessed\")\n",
    "    # Hyperparameters\n",
    "    window_size = 2\n",
    "    batch_size = 5000\n",
    "    total_negative_samples = 10000\n",
    "\n",
    "    # Prepare dataset and dataloader\n",
    "    dataset = Word2VecSentenceDataset(corpus, window_size)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    print(\"model loaded\")\n",
    "    return dataset, dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(dataset, dataloader):\n",
    "\n",
    "     embedding_dim = 20\n",
    "     learning_rate = 0.01\n",
    "     epochs = 10\n",
    "\n",
    "     vocab_size = len(dataset.vocab)\n",
    "     model = Word2VecModel(vocab_size, embedding_dim)\n",
    "     \n",
    "     optimizer = optim.SparseAdam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "     # Example training loop\n",
    "     for epoch in range(epochs):\n",
    "          total_loss = 0\n",
    "          for target, context, negatives in tqdm(dataloader):  \n",
    "               model.zero_grad()\n",
    "               loss = model(target, context, negatives)\n",
    "               loss.backward()\n",
    "               optimizer.step()\n",
    "               total_loss += loss.item()\n",
    "               \n",
    "          \n",
    "          print(f\"Epoch {epoch}, Loss: {total_loss}\")\n",
    "\n",
    "     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed\n",
      "model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [01:21<00:00,  8.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 849.9680168926716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [01:25<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 245.8645165860653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [01:24<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 205.25545005500317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [01:24<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 192.76511053740978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [01:38<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 185.80170972645283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [01:38<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 180.20911352336407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [01:18<00:00,  9.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 175.49111561477184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [01:13<00:00,  9.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 171.24921622872353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [01:13<00:00,  9.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 167.71086248755455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [01:17<00:00,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 164.59217229485512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dataset import Word2VecSentenceDataset\n",
    "\n",
    "dataset, dataloader = prepare_dataset()\n",
    "model = train(dataset, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed\n",
      "model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7003/7003 [01:21<00:00, 85.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 5024.479638680816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7003/7003 [01:15<00:00, 92.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2165.785257384181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7003/7003 [01:19<00:00, 88.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1943.2130392044783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7003/7003 [01:21<00:00, 85.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1847.0670467466116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 467/7003 [00:06<01:24, 77.00it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Word2VecSentenceDataset\n\u001b[1;32m      3\u001b[0m dataset, dataloader \u001b[38;5;241m=\u001b[39m prepare_dataset()\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataset, dataloader)\u001b[0m\n\u001b[1;32m     19\u001b[0m      loss \u001b[38;5;241m=\u001b[39m model(target, context, negatives)\n\u001b[1;32m     20\u001b[0m      loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 21\u001b[0m      \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m      total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/optim/sparse_adam.py:87\u001b[0m, in \u001b[0;36mSparseAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;66;03m# record the step after step update\u001b[39;00m\n\u001b[1;32m     85\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 87\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse_adam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m                  \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/optim/_functional.py:66\u001b[0m, in \u001b[0;36msparse_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, state_steps, eps, beta1, beta2, lr, maximize)\u001b[0m\n\u001b[1;32m     64\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39madd_(make_sparse(exp_avg_update_values))\n\u001b[1;32m     65\u001b[0m old_exp_avg_sq_values \u001b[38;5;241m=\u001b[39m exp_avg_sq\u001b[38;5;241m.\u001b[39msparse_mask(grad)\u001b[38;5;241m.\u001b[39m_values()\n\u001b[0;32m---> 66\u001b[0m exp_avg_sq_update_values \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mold_exp_avg_sq_values\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmul_(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m     67\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39madd_(make_sparse(exp_avg_sq_update_values))\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Dense addition again is intended, avoiding another sparse_mask\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from dataset import Word2VecSentenceDataset\n",
    "\n",
    "dataset, dataloader = prepare_dataset()\n",
    "model = train(dataset, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-03-25 17:23:08 92629:1664419 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "100%|██████████| 14/14 [00:00<00:00, 26.90it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 55.40it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 27.98it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 31.78it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 43.92it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 55.88it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 55.77it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 57.32it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 52.41it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 32.12it/s]\n",
      "[W CPUAllocator.cpp:235] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 26.99661350250244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-03-25 17:23:14 92629:1664419 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2024-03-25 17:23:14 92629:1664419 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxxxxxxxxx\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference         5.94%     212.166ms       100.00%        3.570s        3.570s     381.03 Kb     -55.21 Mb             1  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        55.56%        1.984s        70.86%        2.530s      16.866ms       3.79 Mb      -3.72 Mb           150  \n",
      "                         Optimizer.step#SparseAdam.step         1.74%      62.265ms        15.51%     553.593ms       3.954ms     237.50 Kb     -96.65 Mb           140  \n",
      "                                              aten::mul         1.76%      62.940ms        10.54%     376.178ms     158.058us      92.47 Mb      28.08 Mb          2380  \n",
      "                                            aten::stack         6.21%     221.843ms         8.42%     300.674ms     715.890us       3.79 Mb           0 b           420  \n",
      "                                            aten::empty         5.37%     191.692ms         5.37%     191.784ms       0.859us      60.15 Mb      60.15 Mb        223162  \n",
      "                                      aten::sparse_mask         0.10%       3.454ms         5.28%     188.669ms     336.909us      22.62 Mb      -1.12 Mb           560  \n",
      "                                              aten::add         3.66%     130.666ms         5.11%     182.453ms     130.324us      76.52 Mb      14.47 Mb          1400  \n",
      "                                         aten::coalesce         0.10%       3.500ms         3.24%     115.647ms     413.025us      41.65 Mb       1.56 Mb           280  \n",
      "                                        aten::_coalesce         0.91%      32.340ms         3.22%     114.823ms     410.082us      41.65 Mb       2.93 Mb           280  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 3.570s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], profile_memory=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model = train(dataset, dataloader)\n",
    "print(\"xxxxxxxxxx\")\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed\n",
      "1111111111\n",
      "model loaded\n",
      "         29628201 function calls (29628198 primitive calls) in 35.664 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "   349583   19.370    0.000   21.320    0.000 {method 'choice' of 'numpy.random.mtrand.RandomState' objects}\n",
      "  6127074    2.411    0.000    3.237    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/gensim/utils.py:200(<genexpr>)\n",
      "  1080784    1.307    0.000    1.523    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/gensim/utils.py:270(simple_tokenize)\n",
      "  1161192    1.265    0.000    1.789    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/tag/util.py:10(str2tuple)\n",
      "   129847    1.063    0.000    4.300    0.000 {method 'join' of 'str' objects}\n",
      "    57340    0.828    0.000    2.654    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/gensim/utils.py:310(<listcomp>)\n",
      "  6069734    0.826    0.000    0.826    0.000 {built-in method unicodedata.category}\n",
      "    69890    0.674    0.000   22.208    0.000 /var/folders/8v/tw2k9h3n5k5d1stxdsh3q6d00000gn/T/ipykernel_92629/1351017358.py:32(get_negative_samples)\n",
      "   699166    0.652    0.000    0.860    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/numpy/core/numerictypes.py:283(issubclass_)\n",
      "   349583    0.555    0.000    1.456    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/numpy/core/numerictypes.py:357(issubdtype)\n",
      "3610490/3610488    0.477    0.000    0.478    0.000 {built-in method builtins.len}\n",
      "    89332    0.460    0.000    1.365    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:1072(readline)\n",
      "    57340    0.455    0.000    2.244    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/tagged.py:293(<listcomp>)\n",
      "    73007    0.422    0.000    0.422    0.000 {method 'split' of 're.Pattern' objects}\n",
      "   130272    0.390    0.000    0.390    0.000 {method 'read' of '_io.BufferedReader' objects}\n",
      "   699166    0.370    0.000    0.494    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/numpy/core/getlimits.py:484(__new__)\n",
      "    73007    0.291    0.000    0.291    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/tokenize/regexp.py:127(<listcomp>)\n",
      "  1048750    0.249    0.000    0.249    0.000 {built-in method builtins.issubclass}\n",
      "  1161192    0.240    0.000    0.240    0.000 {method 'rfind' of 'str' objects}\n",
      "    15667    0.206    0.000    4.969    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/tagged.py:287(read_block)\n",
      "        1    0.205    0.205   22.443   22.443 /var/folders/8v/tw2k9h3n5k5d1stxdsh3q6d00000gn/T/ipykernel_92629/1351017358.py:17(generate_training_data)\n",
      "   146439    0.205    0.000    0.205    0.000 {method 'tell' of '_io.BufferedReader' objects}\n",
      "  1006282    0.193    0.000    0.193    0.000 {method 'startswith' of 'str' objects}\n",
      "  1023444    0.170    0.000    0.170    0.000 {method 'group' of 're.Match' objects}\n",
      "    57840    0.161    0.000    5.637    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/util.py:271(iterate_from)\n",
      "  1161192    0.158    0.000    0.158    0.000 {method 'upper' of 'str' objects}\n",
      "    57340    0.156    0.000    0.156    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/tagged.py:300(<listcomp>)\n",
      "    99938    0.155    0.000    0.609    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:1323(_read)\n",
      "    57340    0.128    0.000    4.413    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/gensim/utils.py:174(deaccent)\n",
      "    15667    0.126    0.000    0.349    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:1277(tell)\n",
      "   699668    0.124    0.000    0.124    0.000 {method 'get' of 'dict' objects}\n",
      "    73007    0.116    0.000    0.848    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/tokenize/regexp.py:122(tokenize)\n",
      "    15667    0.116    0.000    1.503    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/util.py:602(read_blankline_block)\n",
      "        1    0.107    0.107   13.175   13.175 /var/folders/8v/tw2k9h3n5k5d1stxdsh3q6d00000gn/T/ipykernel_92629/2332327156.py:1(preprocess_brown_corpus)\n",
      "    57340    0.103    0.000    4.570    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/gensim/utils.py:227(tokenize)\n",
      "   565854    0.103    0.000    0.103    0.000 {method 'append' of 'list' objects}\n",
      "    57340    0.088    0.000    7.312    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/gensim/utils.py:288(simple_preprocess)\n",
      "   139754    0.062    0.000    0.062    0.000 {method 'splitlines' of 'str' objects}\n",
      "   130272    0.059    0.000    0.104    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:1361(_incr_decode)\n",
      "    57340    0.046    0.000    0.046    0.000 {method 'finditer' of 're.Pattern' objects}\n",
      "   130272    0.045    0.000    0.045    0.000 {built-in method _codecs.ascii_decode}\n",
      "    15167    0.043    0.000    0.076    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:1237(_char_seek_forward)\n",
      "        1    0.036    0.036   35.664   35.664 /var/folders/8v/tw2k9h3n5k5d1stxdsh3q6d00000gn/T/ipykernel_92629/2147191065.py:1(<module>)\n",
      "      500    0.032    0.000    0.032    0.000 {built-in method io.open}\n",
      "    57341    0.031    0.000    5.670    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/util.py:410(iterate_from)\n",
      "    76835    0.031    0.000    0.031    0.000 {method 'seek' of '_io.BufferedReader' objects}\n",
      "    15667    0.029    0.000    0.070    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:1202(seek)\n",
      "    57340    0.029    0.000    0.039    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/gensim/utils.py:345(any2unicode)\n",
      "   114680    0.028    0.000    0.028    0.000 {built-in method unicodedata.normalize}\n",
      "   133863    0.028    0.000    0.030    0.000 {built-in method builtins.isinstance}\n",
      "    99940    0.028    0.000    0.028    0.000 {method 'endswith' of 'str' objects}\n",
      "    89329    0.022    0.000    0.022    0.000 {method 'strip' of 'str' objects}\n",
      "    51827    0.020    0.000    0.025    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:1296(<genexpr>)\n",
      "    35127    0.020    0.000    0.020    0.000 {built-in method builtins.max}\n",
      "    15167    0.019    0.000    0.044    0.000 {built-in method builtins.sum}\n",
      "    73007    0.019    0.000    0.019    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/tokenize/regexp.py:118(_check_regexp)\n",
      "     1000    0.018    0.000    0.018    0.000 {built-in method posix.stat}\n",
      "    73366    0.016    0.000    0.016    0.000 {method 'pop' of 'list' objects}\n",
      "    57840    0.016    0.000    0.016    0.000 {method 'lower' of 'str' objects}\n",
      "    18960    0.007    0.000    0.007    0.000 {built-in method builtins.min}\n",
      "      500    0.005    0.000    0.005    0.000 {method 'close' of '_io.BufferedReader' objects}\n",
      "     1000    0.004    0.000    0.004    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/compat.py:25(add_py3_data)\n",
      "      500    0.004    0.000    0.012    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:988(__init__)\n",
      "     1000    0.003    0.000    0.036    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/compat.py:39(_decorator)\n",
      "    15667    0.003    0.000    0.003    0.000 {method 'extend' of 'list' objects}\n",
      "        1    0.003    0.003    0.003    0.003 {built-in method _collections._count_elements}\n",
      "      999    0.003    0.000    0.009    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/util.py:217(close)\n",
      "      500    0.002    0.000    0.052    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:323(open)\n",
      "        1    0.002    0.002    0.004    0.004 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/collections/__init__.py:660(update)\n",
      "      500    0.002    0.000    0.006    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:1401(_check_bom)\n",
      "        1    0.002    0.002    0.002    0.002 /var/folders/8v/tw2k9h3n5k5d1stxdsh3q6d00000gn/T/ipykernel_92629/1351017358.py:8(<listcomp>)\n",
      "      500    0.001    0.000    0.002    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/re/__init__.py:272(_compile)\n",
      "        1    0.001    0.001    0.001    0.001 /var/folders/8v/tw2k9h3n5k5d1stxdsh3q6d00000gn/T/ipykernel_92629/1351017358.py:10(<dictcomp>)\n",
      "      500    0.001    0.000    0.002    0.000 <frozen posixpath>:71(join)\n",
      "        1    0.001    0.001   22.453   22.453 /var/folders/8v/tw2k9h3n5k5d1stxdsh3q6d00000gn/T/ipykernel_92629/1351017358.py:7(__init__)\n",
      "      500    0.001    0.000    0.055    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/util.py:202(_open)\n",
      "      500    0.001    0.000    0.008    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/util.py:125(__init__)\n",
      "     1003    0.001    0.000    0.001    0.000 {built-in method _abc._abc_instancecheck}\n",
      "      500    0.001    0.000    0.001    0.000 {method 'sub' of 're.Pattern' objects}\n",
      "      500    0.001    0.000    0.020    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:332(join)\n",
      "      500    0.001    0.000    0.001    0.000 {built-in method _codecs.lookup}\n",
      "        1    0.001    0.001    0.010    0.010 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/tagged.py:99(<listcomp>)\n",
      "      500    0.001    0.000    0.004    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/re/__init__.py:178(sub)\n",
      "        1    0.001    0.001    0.001    0.001 /var/folders/8v/tw2k9h3n5k5d1stxdsh3q6d00000gn/T/ipykernel_92629/1351017358.py:9(<dictcomp>)\n",
      "      500    0.001    0.000    0.003    0.000 <frozen posixpath>:397(abspath)\n",
      "      500    0.001    0.000    0.016    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:302(__init__)\n",
      "        1    0.001    0.001    0.001    0.001 /var/folders/8v/tw2k9h3n5k5d1stxdsh3q6d00000gn/T/ipykernel_92629/1351017358.py:13(<listcomp>)\n",
      "      500    0.001    0.000    0.001    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:1158(__del__)\n",
      "      500    0.001    0.000    0.001    0.000 <frozen posixpath>:389(normpath)\n",
      "      500    0.001    0.000    0.001    0.000 <frozen codecs>:980(getdecoder)\n",
      "      500    0.001    0.000    0.009    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/tagged.py:264(__init__)\n",
      "     1003    0.001    0.000    0.002    0.000 <frozen abc>:117(__instancecheck__)\n",
      "      500    0.001    0.000    0.005    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:1192(close)\n",
      "      500    0.000    0.000    0.001    0.000 <frozen posixpath>:60(isabs)\n",
      "     1000    0.000    0.000    0.001    0.000 <frozen posixpath>:41(_get_sep)\n",
      "      500    0.000    0.000    0.006    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:329(file_size)\n",
      "        1    0.000    0.000    0.021    0.021 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/api.py:195(<listcomp>)\n",
      "      500    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:1177(closed)\n",
      "      500    0.000    0.000    0.012    0.000 <frozen genericpath>:16(exists)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/zmq/sugar/socket.py:621(send)\n",
      "     2000    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
      "      500    0.000    0.000    0.000    0.000 {built-in method posix._path_normpath}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.array}\n",
      "        2    0.000    0.000   35.664   17.832 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3517(run_code)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/api.py:202(<listcomp>)\n",
      "      500    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/api.py:234(encoding)\n",
      "      500    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/util.py:236(__len__)\n",
      "        1    0.000    0.000    0.021    0.021 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/api.py:172(abspaths)\n",
      "        1    0.000    0.000   35.628   35.628 /var/folders/8v/tw2k9h3n5k5d1stxdsh3q6d00000gn/T/ipykernel_92629/2396163106.py:1(prepare_dataset)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "        6    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/ipykernel/iostream.py:626(write)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/util.py:446(<setcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:225(__init__)\n",
      "    20/19    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:416(__setattr__)\n",
      "        1    0.000    0.000    0.004    0.004 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/collections/__init__.py:587(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/ipykernel/iostream.py:259(schedule)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/util.py:434(concat)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "        1    0.000    0.000    0.031    0.031 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/tagged.py:91(sents)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/codeop.py:120(__call__)\n",
      "        6    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/ipykernel/iostream.py:521(_is_master_process)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/threading.py:1192(is_alive)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/traitlets/traitlets.py:677(__get__)\n",
      "        6    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/ipykernel/iostream.py:548(_schedule_flush)\n",
      "        2    0.000    0.000   35.664   17.832 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._log_api_usage_once}\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/contextlib.py:104(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/threading.py:1125(_wait_for_tstate_lock)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.set_vital}\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/traitlets/traitlets.py:630(get)\n",
      "        1    0.000    0.000    0.031    0.031 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/api.py:408(sents)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/ipykernel/iostream.py:137(_event_pipe)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/sampler.py:129(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/contextlib.py:141(__exit__)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/contextlib.py:299(helper)\n",
      "        4    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/IPython/core/compilerop.py:180(extra_flags)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/numpy/core/_methods.py:47(_sum)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/contextlib.py:132(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/sampler.py:256(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3469(compare)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/util.py:449(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.all}\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py:1255(user_global_ns)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/collections.py:176(__iter__)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/sampler.py:142(num_samples)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:485(check_worker_number_rationality)\n",
      "        2    0.000    0.000    0.000    0.000 /var/folders/8v/tw2k9h3n5k5d1stxdsh3q6d00000gn/T/ipykernel_92629/1351017358.py:40(__len__)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/threading.py:575(is_set)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:392(multiprocessing_context)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _bisect.bisect_right}\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/util.py:384(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/typing.py:2268(cast)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:440(_auto_collation)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/api.py:394(_resolve)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x105341090>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "# Create a Profile object\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "# The code you want to profile\n",
    "prepare_dataset()\n",
    "\n",
    "profiler.disable()\n",
    "\n",
    "# Create Stats object\n",
    "stats = pstats.Stats(profiler).sort_stats('time')\n",
    "\n",
    "# Print the statistics\n",
    "stats.print_stats()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.8405e-01,  9.8905e-02, -3.3643e-01, -1.5944e+00,  8.0877e-01,\n",
      "        -2.1713e+00,  7.2223e-01, -6.2445e-01, -1.0976e+00,  2.6209e-01,\n",
      "         9.4365e-04,  2.1053e+00,  8.8264e-04,  2.4814e-01, -7.1435e-01,\n",
      "         8.6160e-01,  3.6904e-01, -1.6685e+00, -9.4704e-02, -1.3241e+00])\n"
     ]
    }
   ],
   "source": [
    "# Inspect embeddings\n",
    "word_embeddings = model.target_embeddings.weight.data\n",
    "print(word_embeddings[dataset.vocab[\"atlanta\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def find_most_similar(word, word_to_int, int_to_word, embeddings, top_n=5):\n",
    "    # Get the embedding for the given word\n",
    "    word_idx = word_to_int[word]\n",
    "    word_embedding = embeddings[word_idx].reshape(1, -1)\n",
    "    \n",
    "    # Calculate cosine similarity between this word and all other words in the vocabulary\n",
    "    similarities = []\n",
    "    for i in range(len(embeddings)):\n",
    "        other_word_embedding = embeddings[i].reshape(1, -1)\n",
    "        similarity = cosine_similarity(word_embedding, other_word_embedding)[0][0]\n",
    "        similarities.append((i, similarity))\n",
    "    \n",
    "    # Sort by similarity\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Convert indices back to words and filter out the input word\n",
    "    similar_words = [(int_to_word[sim[0]], sim[1]) for sim in similarities if sim[0] != word_idx]\n",
    "    \n",
    "    # Return the top N most similar words, excluding the word itself\n",
    "    return similar_words[:top_n]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'angry': [('goggle', 0.88218176), ('sup', 0.87773263), ('psychosomatic', 0.87381506), ('maximilian', 0.8635538), ('repent', 0.8627277)]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "word = 'angry'  # The word you want to find similar words for\n",
    "similar_words = find_most_similar(word, dataset.vocab, dataset.index_to_word, word_embeddings, top_n=5)\n",
    "print(f\"Most similar words to '{word}':\", similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
