{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from nltk.corpus import brown\n",
    "from  gensim.utils import simple_preprocess\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_words = brown.words()\n",
    "brown_text = \" \".join(brown.words()).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sentences: 57340\n"
     ]
    }
   ],
   "source": [
    "num_sents = len(brown.sents())\n",
    "print(\"number of sentences:\", num_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41239"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(simple_preprocess(brown_text.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'y']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {\"x\":4, \"y\":3}\n",
    "list(a.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Word2VecModel, self).__init__()\n",
    "        self.target_embeddings = nn.Embedding(vocab_size, embedding_dim, sparse=True)\n",
    "        self.context_embeddings = nn.Embedding(vocab_size, embedding_dim, sparse=True)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.target_embeddings.weight.data.uniform_(-1, 1)\n",
    "        self.context_embeddings.weight.data.uniform_(-1, 1)\n",
    "\n",
    "    def forward(self, target_words, context_words, negative_words):\n",
    "        target_embeds = self.target_embeddings(target_words)\n",
    "        context_embeds = self.context_embeddings(context_words)\n",
    "        negative_embeds = self.context_embeddings(negative_words)\n",
    "\n",
    "        positive_score = torch.sum(target_embeds * context_embeds, dim=1)\n",
    "        negative_score = torch.bmm(negative_embeds, target_embeds.unsqueeze(2)).squeeze()\n",
    "\n",
    "        return -torch.mean(torch.log(torch.sigmoid(positive_score)) + torch.sum(torch.log(torch.sigmoid(-negative_score)), dim=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_brown_corpus():\n",
    "    processed_sentences = []\n",
    "    for sentence in brown.sents():\n",
    "        processed_sentence = simple_preprocess(' '.join(sentence), deacc=True)  \n",
    "        processed_sentences.append(processed_sentence)\n",
    "    return processed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch_size=512, window_size=5, negative_samples=5, total_negative_samples=10000):\n",
    "    # Example corpus\n",
    "    corpus = preprocess_brown_corpus()\n",
    "    print(\"preprocessed\")\n",
    "    # Hyperparameters\n",
    "    \n",
    "\n",
    "    # Prepare dataset and dataloader\n",
    "    dataset = Word2VecSentenceDataset(corpus, window_size, negative_samples, total_negative_samples)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    print(\"model loaded\")\n",
    "    return dataset, dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(dataset, dataloader, epochs = 10, embedding_dim = 20):\n",
    "\n",
    "     \n",
    "     learning_rate = 0.01\n",
    "\n",
    "     vocab_size = len(dataset.vocab)\n",
    "     model = Word2VecModel(vocab_size, embedding_dim)\n",
    "     \n",
    "     optimizer = optim.SparseAdam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "     # Example training loop\n",
    "     for epoch in range(epochs):\n",
    "          total_loss = 0\n",
    "          for target, context, negatives in tqdm(dataloader):  \n",
    "               model.zero_grad()\n",
    "               loss = model(target, context, negatives)\n",
    "               loss.backward()\n",
    "               optimizer.step()\n",
    "               total_loss += loss.item()\n",
    "               \n",
    "          \n",
    "          print(f\"Epoch {epoch}, Loss: {total_loss}\")\n",
    "\n",
    "     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed\n",
      "model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15925/15925 [03:13<00:00, 82.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 8205.604247227311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15925/15925 [03:16<00:00, 81.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4845.350632846355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15925/15925 [03:53<00:00, 68.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 4641.762401416898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15925/15925 [04:47<00:00, 55.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 4491.427864342928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15925/15925 [04:14<00:00, 62.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 4375.1427896767855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dataset import Word2VecSentenceDataset\n",
    "\n",
    "dataset, dataloader = prepare_dataset(batch_size=512, window_size=5, negative_samples=5, total_negative_samples=10000)\n",
    "model = train(dataset, dataloader, epochs=5, embedding_dim = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], profile_memory=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model = train(dataset, dataloader)\n",
    "print(\"xxxxxxxxxx\")\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "# Create a Profile object\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "# The code you want to profile\n",
    "prepare_dataset()\n",
    "\n",
    "profiler.disable()\n",
    "\n",
    "# Create Stats object\n",
    "stats = pstats.Stats(profiler).sort_stats('time')\n",
    "\n",
    "# Print the statistics\n",
    "stats.print_stats()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8798, -0.0981, -0.0641, -0.6053, -0.0116,  0.1742,  0.4074, -0.1351,\n",
      "        -0.3801,  0.5048, -1.6327,  0.0111, -0.0943, -0.1630,  1.1513,  0.1729,\n",
      "        -0.1996, -0.7478, -1.0341,  0.5263,  0.4483,  0.1727,  1.0539, -0.1429,\n",
      "        -0.2299,  0.7460,  0.1045,  0.5899, -0.3256, -0.1430])\n"
     ]
    }
   ],
   "source": [
    "# Inspect embeddings\n",
    "word_embeddings = model.target_embeddings.weight.data\n",
    "print(word_embeddings[dataset.vocab[\"atlanta\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def find_most_similar(word, word_to_int, int_to_word, embeddings, top_n=5):\n",
    "    # Get the embedding for the given word\n",
    "    word_idx = word_to_int[word]\n",
    "    word_embedding = embeddings[word_idx].reshape(1, -1)\n",
    "    \n",
    "    # Calculate cosine similarity between this word and all other words in the vocabulary\n",
    "    similarities = []\n",
    "    for i in range(len(embeddings)):\n",
    "        other_word_embedding = embeddings[i].reshape(1, -1)\n",
    "        similarity = cosine_similarity(word_embedding, other_word_embedding)[0][0]\n",
    "        similarities.append((i, similarity))\n",
    "    \n",
    "    # Sort by similarity\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Convert indices back to words and filter out the input word\n",
    "    similar_words = [(int_to_word[sim[0]], sim[1]) for sim in similarities if sim[0] != word_idx]\n",
    "    \n",
    "    # Return the top N most similar words, excluding the word itself\n",
    "    return similar_words[:top_n]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'book': [('comedie', 0.8072341), ('trempler', 0.8050022), ('often', 0.80381423), ('expe', 0.8015127), ('hors', 0.80094683)]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "word = 'book'  # The word you want to find similar words for\n",
    "similar_words = find_most_similar(word, dataset.vocab, dataset.index_to_word, word_embeddings, top_n=5)\n",
    "print(f\"Most similar words to '{word}':\", similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'twenty': [('thirty', 0.8679474), ('ten', 0.8436272), ('six', 0.8391596), ('laid', 0.8352573), ('five', 0.82961893)]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "word = 'twenty'  # The word you want to find similar words for\n",
    "similar_words = find_most_similar(word, dataset.vocab, dataset.index_to_word, word_embeddings, top_n=5)\n",
    "print(f\"Most similar words to '{word}':\", similar_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
