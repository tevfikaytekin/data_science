{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from nltk.corpus import brown\n",
    "from  gensim.utils import simple_preprocess\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from dataset import Word2VecSentenceDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_words = brown.words()\n",
    "brown_text = \" \".join(brown.words()).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sentences: 57340\n"
     ]
    }
   ],
   "source": [
    "num_sents = len(brown.sents())\n",
    "print(\"number of sentences:\", num_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41239"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(simple_preprocess(brown_text.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'y']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {\"x\":4, \"y\":3}\n",
    "list(a.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Word2VecModel, self).__init__()\n",
    "        self.target_embeddings = nn.Embedding(vocab_size, embedding_dim, sparse=True)\n",
    "        self.context_embeddings = nn.Embedding(vocab_size, embedding_dim, sparse=True)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.target_embeddings.weight.data.uniform_(-1, 1)\n",
    "        self.context_embeddings.weight.data.uniform_(-1, 1)\n",
    "\n",
    "    def forward(self, target_words, context_words, negative_words):\n",
    "        target_embeds = self.target_embeddings(target_words)\n",
    "        context_embeds = self.context_embeddings(context_words)\n",
    "        negative_embeds = self.context_embeddings(negative_words)\n",
    " \n",
    "\n",
    "        positive_score = torch.sum(target_embeds * context_embeds, dim=1)\n",
    "        negative_score = torch.bmm(negative_embeds, target_embeds.unsqueeze(2)).squeeze()\n",
    "   \n",
    "        return -torch.mean(torch.log(torch.sigmoid(positive_score)) + torch.sum(torch.log(torch.sigmoid(-negative_score)), dim=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_brown_corpus():\n",
    "    processed_sentences = []\n",
    "    for sentence in brown.sents():\n",
    "        processed_sentence = simple_preprocess(' '.join(sentence), deacc=True)  \n",
    "        processed_sentences.append(processed_sentence)\n",
    "    return processed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = preprocess_brown_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = Word2VecSentenceDataset(corpus, window_size=2, negative_samples=5, total_negative_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'fulton',\n",
       " 'county',\n",
       " 'grand',\n",
       " 'jury',\n",
       " 'said',\n",
       " 'friday',\n",
       " 'an',\n",
       " 'investigation',\n",
       " 'of']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dataset.tokens))\n",
    "dataset.tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3585262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(26233, 27914, [31431, 233, 808, 24462, 84]),\n",
       " (26233, 36134, [541, 1670, 2709, 272, 133]),\n",
       " (27914, 26233, [21181, 189, 13242, 17735, 248]),\n",
       " (27914, 36134, [7817, 2524, 17259, 6651, 295]),\n",
       " (27914, 1268, [6283, 18, 791, 9, 2658]),\n",
       " (36134, 26233, [15651, 163, 26752, 382, 6714]),\n",
       " (36134, 27914, [77, 24434, 6909, 39571, 4480]),\n",
       " (36134, 1268, [3856, 28778, 9328, 1517, 6790]),\n",
       " (36134, 23855, [1855, 35741, 2812, 0, 47]),\n",
       " (1268, 27914, [23, 6248, 38490, 4090, 357])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dataset.data))\n",
    "dataset.data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch_size=512, window_size=5, negative_samples=5, total_negative_samples=10000):\n",
    "    # Example corpus\n",
    "    corpus = preprocess_brown_corpus()\n",
    "    print(\"preprocessed\")\n",
    "    # Hyperparameters\n",
    "    \n",
    "\n",
    "    # Prepare dataset and dataloader\n",
    "    dataset = Word2VecSentenceDataset(corpus, window_size, negative_samples, total_negative_samples)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    print(\"model loaded\")\n",
    "    return dataset, dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(dataset, dataloader, epochs = 10, embedding_dim = 20):\n",
    "\n",
    "     \n",
    "     learning_rate = 0.01\n",
    "\n",
    "     vocab_size = len(dataset.vocab)\n",
    "     model = Word2VecModel(vocab_size, embedding_dim)\n",
    "     \n",
    "     optimizer = optim.SparseAdam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "     # Example training loop\n",
    "     for epoch in range(epochs):\n",
    "          total_loss = 0\n",
    "          for target, context, negatives in tqdm(dataloader):  \n",
    "               model.zero_grad()\n",
    "               loss = model(target, context, negatives)\n",
    "               loss.backward()\n",
    "               optimizer.step()\n",
    "               total_loss += loss.item()\n",
    "               print(loss.item())\n",
    "          \n",
    "          print(f\"Epoch {epoch}, Loss: {total_loss}\")\n",
    "\n",
    "     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset, dataloader = prepare_dataset(batch_size=512, window_size=5, negative_samples=5, total_negative_samples=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/15925 [00:01<2:03:04,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.118812084197998\n",
      "6.028980731964111\n",
      "6.191402912139893\n",
      "6.031180381774902\n",
      "5.911285400390625\n",
      "6.005388259887695\n",
      "6.007167816162109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13/15925 [00:01<14:53, 17.82it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.042276382446289\n",
      "5.818857669830322\n",
      "5.85860013961792\n",
      "5.959985256195068\n",
      "5.985980033874512\n",
      "5.8998847007751465\n",
      "5.8394880294799805\n",
      "5.743626117706299\n",
      "6.018033981323242\n",
      "5.513816833496094\n",
      "5.858908653259277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 25/15925 [00:01<08:14, 32.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.482419013977051\n",
      "5.76649284362793\n",
      "5.814390659332275\n",
      "5.590760231018066\n",
      "5.635128021240234\n",
      "5.743924140930176\n",
      "5.92970085144043\n",
      "5.704176425933838\n",
      "5.752326488494873\n",
      "5.488264083862305\n",
      "5.671124458312988\n",
      "5.5727105140686035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 38/15925 [00:01<06:08, 43.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.724306106567383\n",
      "5.686717987060547\n",
      "5.469682693481445\n",
      "5.637192249298096\n",
      "5.618267059326172\n",
      "5.520267486572266\n",
      "5.357206344604492\n",
      "5.532052040100098\n",
      "5.579288482666016\n",
      "5.504079341888428\n",
      "5.59511137008667\n",
      "5.421290397644043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 50/15925 [00:01<05:19, 49.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.529731750488281\n",
      "5.488776683807373\n",
      "5.491903305053711\n",
      "5.340784072875977\n",
      "5.432787895202637\n",
      "5.507948398590088\n",
      "5.32711935043335\n",
      "5.42296838760376\n",
      "5.379973888397217\n",
      "5.3936686515808105\n",
      "5.4688591957092285\n",
      "5.363813877105713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 62/15925 [00:02<05:38, 46.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.376306533813477\n",
      "5.443447113037109\n",
      "5.362707614898682\n",
      "5.394664764404297\n",
      "5.330791473388672\n",
      "5.315066337585449\n",
      "5.209598541259766\n",
      "5.289705276489258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 68/15925 [00:02<06:43, 39.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.258356094360352\n",
      "5.4281792640686035\n",
      "5.232609748840332\n",
      "5.090364456176758\n",
      "5.167248249053955\n",
      "5.074770927429199\n",
      "5.135268211364746\n",
      "5.148684024810791\n",
      "5.145553112030029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 77/15925 [00:03<10:32, 25.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.234455108642578\n",
      "5.158916473388672\n",
      "5.1948442459106445\n",
      "5.187009334564209\n",
      "5.044800281524658\n",
      "5.196109771728516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 81/15925 [00:03<10:08, 26.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.965250015258789\n",
      "4.943820953369141\n",
      "4.967985153198242\n",
      "5.148873329162598\n",
      "5.027953147888184\n",
      "4.978152275085449\n",
      "5.0746541023254395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 89/15925 [00:03<08:44, 30.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.002896785736084\n",
      "4.7722978591918945\n",
      "5.003775596618652\n",
      "4.933221340179443\n",
      "4.972075939178467\n",
      "4.864471435546875\n",
      "5.097987174987793\n",
      "4.9611029624938965\n",
      "4.849127769470215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 99/15925 [00:03<07:27, 35.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.861113548278809\n",
      "4.815537929534912\n",
      "4.9008097648620605\n",
      "4.871829986572266\n",
      "4.904585838317871\n",
      "4.88133430480957\n",
      "4.9160237312316895\n",
      "4.7247233390808105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 107/15925 [00:03<07:18, 36.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.949332237243652\n",
      "4.73650598526001\n",
      "4.816738128662109\n",
      "4.790104866027832\n",
      "4.803312301635742\n",
      "4.774954795837402\n",
      "4.824333190917969\n",
      "4.786520957946777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 116/15925 [00:04<07:03, 37.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.71120023727417\n",
      "4.615214824676514\n",
      "4.711833477020264\n",
      "4.6290788650512695\n",
      "4.885652542114258\n",
      "4.599153995513916\n",
      "4.615567684173584\n",
      "4.605502128601074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 125/15925 [00:04<06:30, 40.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.560319900512695\n",
      "4.520665168762207\n",
      "4.528570175170898\n",
      "4.670169830322266\n",
      "4.570208549499512\n",
      "4.493706226348877\n",
      "4.600646018981934\n",
      "4.6966986656188965\n",
      "4.469510078430176\n",
      "4.525454998016357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 134/15925 [00:04<06:45, 38.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.390516757965088\n",
      "4.60860538482666\n",
      "4.424403190612793\n",
      "4.383378028869629\n",
      "4.167551040649414\n",
      "4.471012115478516\n",
      "4.322669982910156\n",
      "4.363311767578125\n",
      "4.3353729248046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 143/15925 [00:05<11:33, 22.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.325016975402832\n",
      "4.445796012878418\n",
      "4.201120853424072\n",
      "4.329587459564209\n",
      "4.443479061126709\n",
      "4.2860565185546875\n",
      "4.2542829513549805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 152/15925 [00:05<08:53, 29.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.248330116271973\n",
      "4.387728691101074\n",
      "4.068804740905762\n",
      "4.1061530113220215\n",
      "4.211218357086182\n",
      "4.220152378082275\n",
      "4.283351898193359\n",
      "4.194844722747803\n",
      "4.190384387969971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 156/15925 [00:05<08:56, 29.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.234819412231445\n",
      "4.171573162078857\n",
      "4.113008499145508\n",
      "4.211209297180176\n",
      "3.9524598121643066\n",
      "4.060318946838379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 164/15925 [00:05<08:22, 31.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.140848636627197\n",
      "4.013000011444092\n",
      "3.8698179721832275\n",
      "3.8773651123046875\n",
      "4.129438400268555\n",
      "3.835348606109619\n",
      "4.016602516174316\n",
      "3.9354169368743896\n",
      "3.776674270629883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 172/15925 [00:05<09:01, 29.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.013361930847168\n",
      "3.954721450805664\n",
      "3.7807536125183105\n",
      "3.781461715698242\n",
      "3.593843460083008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataset, dataloader, epochs, embedding_dim)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     15\u001b[0m      total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 16\u001b[0m \u001b[43m     \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegatives\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m          \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m          \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegatives\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1185\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Documents/data_science/nlp/pytorch/dataset.py:50\u001b[0m, in \u001b[0;36mWord2VecSentenceDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     49\u001b[0m     target, context, negatives \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx]\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(target, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong), \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m, torch\u001b[38;5;241m.\u001b[39mtensor(negatives, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = train(dataset, dataloader, epochs=5, embedding_dim = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], profile_memory=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model = train(dataset, dataloader)\n",
    "print(\"xxxxxxxxxx\")\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "# Create a Profile object\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "# The code you want to profile\n",
    "prepare_dataset()\n",
    "\n",
    "profiler.disable()\n",
    "\n",
    "# Create Stats object\n",
    "stats = pstats.Stats(profiler).sort_stats('time')\n",
    "\n",
    "# Print the statistics\n",
    "stats.print_stats()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8798, -0.0981, -0.0641, -0.6053, -0.0116,  0.1742,  0.4074, -0.1351,\n",
      "        -0.3801,  0.5048, -1.6327,  0.0111, -0.0943, -0.1630,  1.1513,  0.1729,\n",
      "        -0.1996, -0.7478, -1.0341,  0.5263,  0.4483,  0.1727,  1.0539, -0.1429,\n",
      "        -0.2299,  0.7460,  0.1045,  0.5899, -0.3256, -0.1430])\n"
     ]
    }
   ],
   "source": [
    "# Inspect embeddings\n",
    "word_embeddings = model.target_embeddings.weight.data\n",
    "print(word_embeddings[dataset.vocab[\"atlanta\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def find_most_similar(word, word_to_int, int_to_word, embeddings, top_n=5):\n",
    "    # Get the embedding for the given word\n",
    "    word_idx = word_to_int[word]\n",
    "    word_embedding = embeddings[word_idx].reshape(1, -1)\n",
    "    \n",
    "    # Calculate cosine similarity between this word and all other words in the vocabulary\n",
    "    similarities = []\n",
    "    for i in range(len(embeddings)):\n",
    "        other_word_embedding = embeddings[i].reshape(1, -1)\n",
    "        similarity = cosine_similarity(word_embedding, other_word_embedding)[0][0]\n",
    "        similarities.append((i, similarity))\n",
    "    \n",
    "    # Sort by similarity\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Convert indices back to words and filter out the input word\n",
    "    similar_words = [(int_to_word[sim[0]], sim[1]) for sim in similarities if sim[0] != word_idx]\n",
    "    \n",
    "    # Return the top N most similar words, excluding the word itself\n",
    "    return similar_words[:top_n]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'book': [('comedie', 0.8072341), ('trempler', 0.8050022), ('often', 0.80381423), ('expe', 0.8015127), ('hors', 0.80094683)]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "word = 'book'  # The word you want to find similar words for\n",
    "similar_words = find_most_similar(word, dataset.vocab, dataset.index_to_word, word_embeddings, top_n=5)\n",
    "print(f\"Most similar words to '{word}':\", similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'twenty': [('thirty', 0.8679474), ('ten', 0.8436272), ('six', 0.8391596), ('laid', 0.8352573), ('five', 0.82961893)]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "word = 'twenty'  # The word you want to find similar words for\n",
    "similar_words = find_most_similar(word, dataset.vocab, dataset.index_to_word, word_embeddings, top_n=5)\n",
    "print(f\"Most similar words to '{word}':\", similar_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
