{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from nltk.corpus import brown\n",
    "from  gensim.utils import simple_preprocess\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_words = brown.words()\n",
    "brown_text = \" \".join(brown.words()).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sentences: 57340\n"
     ]
    }
   ],
   "source": [
    "num_sents = len(brown.sents())\n",
    "print(\"number of sentences:\", num_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41239"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(simple_preprocess(brown_text.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class Word2VecSentenceDataset_bak(Dataset):\n",
    "    def __init__(self, sentences, window_size=2, negative_samples=5):\n",
    "        \"\"\"\n",
    "        sentences: List of sentences, where each sentence is a list of words.\n",
    "        window_size: The size of the context window.\n",
    "        negative_samples: Number of negative samples to generate for each positive pair.\n",
    "        \"\"\"\n",
    "        self.tokens = [word for sentence in sentences for word in sentence]  # Flatten the list of sentences\n",
    "        self.vocab = {word: i for i, word in enumerate(set(self.tokens))}\n",
    "        self.index_to_word = {i: word for word, i in self.vocab.items()}\n",
    "        self.window_size = window_size\n",
    "        self.negative_samples = negative_samples\n",
    "        self.word_frequencies = np.array([freq for word, freq in Counter(self.tokens).items()])**0.75\n",
    "        self.word_frequencies /= self.word_frequencies.sum()\n",
    "        self.data = self.generate_training_data(sentences)\n",
    "\n",
    "    def generate_training_data(self, sentences):\n",
    "        positive_pairs = []\n",
    "        for sentence in sentences:\n",
    "            for i, target_word in enumerate(sentence):\n",
    "                target_index = self.vocab[target_word]\n",
    "                context_indices = range(max(0, i - self.window_size), min(len(sentence), i + self.window_size + 1))\n",
    "                for j in context_indices:\n",
    "                    if i != j:  # Exclude the target word itself\n",
    "                        context_word = sentence[j]\n",
    "                        context_index = self.vocab[context_word]\n",
    "                        positive_pairs.append((target_index, context_index))\n",
    "        return positive_pairs\n",
    "\n",
    "    def get_negative_samples(self, target, num_samples):\n",
    "        negatives = []\n",
    "        while len(negatives) < num_samples:\n",
    "            neg_sample = np.random.choice(len(self.vocab), p=self.word_frequencies)\n",
    "            if neg_sample != target:\n",
    "                negatives.append(neg_sample)\n",
    "        return negatives\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        target, context = self.data[idx]\n",
    "        negatives = self.get_negative_samples(target, self.negative_samples)\n",
    "        return torch.tensor(target, dtype=torch.long), torch.tensor(context, dtype=torch.long), torch.tensor(negatives, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'y']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {\"x\":4, \"y\":3}\n",
    "list(a.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class Word2VecSentenceDataset(Dataset):\n",
    "    def __init__(self, sentences, window_size=2, negative_samples=5, total_negative_samples=10000):\n",
    "        self.tokens = [word for sentence in sentences for word in sentence]\n",
    "        self.vocab = {word: i for i, word in enumerate(set(self.tokens))}\n",
    "        self.index_to_word = {i: word for word, i in self.vocab.items()}\n",
    "        self.window_size = window_size\n",
    "        self.negative_samples = negative_samples\n",
    "        self.word_frequencies = np.array([freq for word, freq in Counter(self.tokens).items()])**0.75\n",
    "        self.word_frequencies /= self.word_frequencies.sum()\n",
    "        self.negative_sample_pool = np.random.choice(len(self.word_frequencies), size=total_negative_samples, replace=True, p=self.word_frequencies).tolist()\n",
    "\n",
    "        self.data = self.generate_training_data(sentences)\n",
    "\n",
    "    def generate_training_data(self, sentences):\n",
    "        training_data = []\n",
    "        for sentence in sentences:\n",
    "            for i, target_word in enumerate(sentence):\n",
    "                target_index = self.vocab[target_word]\n",
    "                context_indices = range(max(0, i - self.window_size), min(len(sentence), i + self.window_size + 1))\n",
    "                for j in context_indices:\n",
    "                    if i != j:  # Exclude the target word itself\n",
    "                        context_word = sentence[j]\n",
    "                        context_index = self.vocab[context_word]\n",
    "\n",
    "                        negative_samples = random.sample(self.negative_sample_pool, k=self.negative_samples)\n",
    "                        #negative_samples = self.get_negative_samples(target_index, self.negative_samples)\n",
    "                        training_data.append((target_index, context_index, negative_samples))\n",
    "   \n",
    "        return training_data\n",
    "\n",
    "    def get_negative_samples(self, target, num_samples):\n",
    "        negatives = []\n",
    "        while len(negatives) < num_samples:\n",
    "            neg_sample = np.random.choice(len(self.vocab), p=self.word_frequencies)\n",
    "            if neg_sample != target:\n",
    "                negatives.append(neg_sample)\n",
    "        return negatives\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        target, context, negatives = self.data[idx]\n",
    "        return torch.tensor(target, dtype=torch.long), torch.tensor(context, dtype=torch.long), torch.tensor(negatives, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Word2VecModel, self).__init__()\n",
    "        self.target_embeddings = nn.Embedding(vocab_size, embedding_dim, sparse=True)\n",
    "        self.context_embeddings = nn.Embedding(vocab_size, embedding_dim, sparse=True)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.target_embeddings.weight.data.uniform_(-1, 1)\n",
    "        self.context_embeddings.weight.data.uniform_(-1, 1)\n",
    "\n",
    "    def forward(self, target_words, context_words, negative_words):\n",
    "        target_embeds = self.target_embeddings(target_words)\n",
    "        context_embeds = self.context_embeddings(context_words)\n",
    "        negative_embeds = self.context_embeddings(negative_words)\n",
    "\n",
    "        positive_score = torch.sum(target_embeds * context_embeds, dim=1)\n",
    "        negative_score = torch.bmm(negative_embeds, target_embeds.unsqueeze(2)).squeeze()\n",
    "\n",
    "        return -torch.mean(torch.log(torch.sigmoid(positive_score)) + torch.sum(torch.log(torch.sigmoid(-negative_score)), dim=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_brown_corpus():\n",
    "    processed_sentences = []\n",
    "    for sentence in brown.sents():\n",
    "        processed_sentence = simple_preprocess(' '.join(sentence), deacc=True)  \n",
    "        processed_sentences.append(processed_sentence)\n",
    "    return processed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset():\n",
    "    # Example corpus\n",
    "    corpus = preprocess_brown_corpus()\n",
    "    print(\"preprocessed\")\n",
    "    # Hyperparameters\n",
    "    window_size = 2\n",
    "    batch_size = 512\n",
    "    total_negative_samples = 10000\n",
    "\n",
    "    # Prepare dataset and dataloader\n",
    "    dataset = Word2VecSentenceDataset(corpus, window_size)\n",
    "    print(\"1111111111\")\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    print(\"model loaded\")\n",
    "    return dataset, dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(dataset, dataloader):\n",
    "\n",
    "     embedding_dim = 20\n",
    "     learning_rate = 0.01\n",
    "     epochs = 10\n",
    "\n",
    "     vocab_size = len(dataset.vocab)\n",
    "     model = Word2VecModel(vocab_size, embedding_dim)\n",
    "     \n",
    "     optimizer = optim.SparseAdam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "     # Example training loop\n",
    "     for epoch in range(epochs):\n",
    "          total_loss = 0\n",
    "          for target, context, negatives in tqdm(dataloader):  \n",
    "               model.zero_grad()\n",
    "               loss = model(target, context, negatives)\n",
    "               loss.backward()\n",
    "               optimizer.step()\n",
    "               total_loss += loss.item()\n",
    "               \n",
    "          \n",
    "     print(f\"Epoch {epoch}, Loss: {total_loss}\")\n",
    "\n",
    "     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed\n",
      "1111111111\n",
      "model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 4102/7003 [00:57<00:40, 71.91it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset, dataloader \u001b[38;5;241m=\u001b[39m prepare_dataset()\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[85], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataset, dataloader)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     16\u001b[0m      total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[43m     \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegatives\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m          \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m          \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegatives\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1185\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[102], line 49\u001b[0m, in \u001b[0;36mWord2VecSentenceDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     48\u001b[0m     target, context, negatives \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx]\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(target, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong), torch\u001b[38;5;241m.\u001b[39mtensor(context, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong), \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnegatives\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset, dataloader = prepare_dataset()\n",
    "model = train(dataset, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-03-25 17:23:08 92629:1664419 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "100%|██████████| 14/14 [00:00<00:00, 26.90it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 55.40it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 27.98it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 31.78it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 43.92it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 55.88it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 55.77it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 57.32it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 52.41it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 32.12it/s]\n",
      "[W CPUAllocator.cpp:235] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 26.99661350250244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-03-25 17:23:14 92629:1664419 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2024-03-25 17:23:14 92629:1664419 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxxxxxxxxx\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference         5.94%     212.166ms       100.00%        3.570s        3.570s     381.03 Kb     -55.21 Mb             1  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        55.56%        1.984s        70.86%        2.530s      16.866ms       3.79 Mb      -3.72 Mb           150  \n",
      "                         Optimizer.step#SparseAdam.step         1.74%      62.265ms        15.51%     553.593ms       3.954ms     237.50 Kb     -96.65 Mb           140  \n",
      "                                              aten::mul         1.76%      62.940ms        10.54%     376.178ms     158.058us      92.47 Mb      28.08 Mb          2380  \n",
      "                                            aten::stack         6.21%     221.843ms         8.42%     300.674ms     715.890us       3.79 Mb           0 b           420  \n",
      "                                            aten::empty         5.37%     191.692ms         5.37%     191.784ms       0.859us      60.15 Mb      60.15 Mb        223162  \n",
      "                                      aten::sparse_mask         0.10%       3.454ms         5.28%     188.669ms     336.909us      22.62 Mb      -1.12 Mb           560  \n",
      "                                              aten::add         3.66%     130.666ms         5.11%     182.453ms     130.324us      76.52 Mb      14.47 Mb          1400  \n",
      "                                         aten::coalesce         0.10%       3.500ms         3.24%     115.647ms     413.025us      41.65 Mb       1.56 Mb           280  \n",
      "                                        aten::_coalesce         0.91%      32.340ms         3.22%     114.823ms     410.082us      41.65 Mb       2.93 Mb           280  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 3.570s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], profile_memory=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model = train(dataset, dataloader)\n",
    "print(\"xxxxxxxxxx\")\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed\n",
      "1111111111\n",
      "model loaded\n",
      "         29628201 function calls (29628198 primitive calls) in 35.664 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "   349583   19.370    0.000   21.320    0.000 {method 'choice' of 'numpy.random.mtrand.RandomState' objects}\n",
      "  6127074    2.411    0.000    3.237    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/gensim/utils.py:200(<genexpr>)\n",
      "  1080784    1.307    0.000    1.523    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/gensim/utils.py:270(simple_tokenize)\n",
      "  1161192    1.265    0.000    1.789    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/tag/util.py:10(str2tuple)\n",
      "   129847    1.063    0.000    4.300    0.000 {method 'join' of 'str' objects}\n",
      "    57340    0.828    0.000    2.654    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/gensim/utils.py:310(<listcomp>)\n",
      "  6069734    0.826    0.000    0.826    0.000 {built-in method unicodedata.category}\n",
      "    69890    0.674    0.000   22.208    0.000 /var/folders/8v/tw2k9h3n5k5d1stxdsh3q6d00000gn/T/ipykernel_92629/1351017358.py:32(get_negative_samples)\n",
      "   699166    0.652    0.000    0.860    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/numpy/core/numerictypes.py:283(issubclass_)\n",
      "   349583    0.555    0.000    1.456    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/numpy/core/numerictypes.py:357(issubdtype)\n",
      "3610490/3610488    0.477    0.000    0.478    0.000 {built-in method builtins.len}\n",
      "    89332    0.460    0.000    1.365    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:1072(readline)\n",
      "    57340    0.455    0.000    2.244    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/tagged.py:293(<listcomp>)\n",
      "    73007    0.422    0.000    0.422    0.000 {method 'split' of 're.Pattern' objects}\n",
      "   130272    0.390    0.000    0.390    0.000 {method 'read' of '_io.BufferedReader' objects}\n",
      "   699166    0.370    0.000    0.494    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/numpy/core/getlimits.py:484(__new__)\n",
      "    73007    0.291    0.000    0.291    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/tokenize/regexp.py:127(<listcomp>)\n",
      "  1048750    0.249    0.000    0.249    0.000 {built-in method builtins.issubclass}\n",
      "  1161192    0.240    0.000    0.240    0.000 {method 'rfind' of 'str' objects}\n",
      "    15667    0.206    0.000    4.969    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/tagged.py:287(read_block)\n",
      "        1    0.205    0.205   22.443   22.443 /var/folders/8v/tw2k9h3n5k5d1stxdsh3q6d00000gn/T/ipykernel_92629/1351017358.py:17(generate_training_data)\n",
      "   146439    0.205    0.000    0.205    0.000 {method 'tell' of '_io.BufferedReader' objects}\n",
      "  1006282    0.193    0.000    0.193    0.000 {method 'startswith' of 'str' objects}\n",
      "  1023444    0.170    0.000    0.170    0.000 {method 'group' of 're.Match' objects}\n",
      "    57840    0.161    0.000    5.637    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/util.py:271(iterate_from)\n",
      "  1161192    0.158    0.000    0.158    0.000 {method 'upper' of 'str' objects}\n",
      "    57340    0.156    0.000    0.156    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/tagged.py:300(<listcomp>)\n",
      "    99938    0.155    0.000    0.609    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:1323(_read)\n",
      "    57340    0.128    0.000    4.413    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/gensim/utils.py:174(deaccent)\n",
      "    15667    0.126    0.000    0.349    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:1277(tell)\n",
      "   699668    0.124    0.000    0.124    0.000 {method 'get' of 'dict' objects}\n",
      "    73007    0.116    0.000    0.848    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/tokenize/regexp.py:122(tokenize)\n",
      "    15667    0.116    0.000    1.503    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/util.py:602(read_blankline_block)\n",
      "        1    0.107    0.107   13.175   13.175 /var/folders/8v/tw2k9h3n5k5d1stxdsh3q6d00000gn/T/ipykernel_92629/2332327156.py:1(preprocess_brown_corpus)\n",
      "    57340    0.103    0.000    4.570    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/gensim/utils.py:227(tokenize)\n",
      "   565854    0.103    0.000    0.103    0.000 {method 'append' of 'list' objects}\n",
      "    57340    0.088    0.000    7.312    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/gensim/utils.py:288(simple_preprocess)\n",
      "   139754    0.062    0.000    0.062    0.000 {method 'splitlines' of 'str' objects}\n",
      "   130272    0.059    0.000    0.104    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:1361(_incr_decode)\n",
      "    57340    0.046    0.000    0.046    0.000 {method 'finditer' of 're.Pattern' objects}\n",
      "   130272    0.045    0.000    0.045    0.000 {built-in method _codecs.ascii_decode}\n",
      "    15167    0.043    0.000    0.076    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:1237(_char_seek_forward)\n",
      "        1    0.036    0.036   35.664   35.664 /var/folders/8v/tw2k9h3n5k5d1stxdsh3q6d00000gn/T/ipykernel_92629/2147191065.py:1(<module>)\n",
      "      500    0.032    0.000    0.032    0.000 {built-in method io.open}\n",
      "    57341    0.031    0.000    5.670    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/util.py:410(iterate_from)\n",
      "    76835    0.031    0.000    0.031    0.000 {method 'seek' of '_io.BufferedReader' objects}\n",
      "    15667    0.029    0.000    0.070    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:1202(seek)\n",
      "    57340    0.029    0.000    0.039    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/gensim/utils.py:345(any2unicode)\n",
      "   114680    0.028    0.000    0.028    0.000 {built-in method unicodedata.normalize}\n",
      "   133863    0.028    0.000    0.030    0.000 {built-in method builtins.isinstance}\n",
      "    99940    0.028    0.000    0.028    0.000 {method 'endswith' of 'str' objects}\n",
      "    89329    0.022    0.000    0.022    0.000 {method 'strip' of 'str' objects}\n",
      "    51827    0.020    0.000    0.025    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:1296(<genexpr>)\n",
      "    35127    0.020    0.000    0.020    0.000 {built-in method builtins.max}\n",
      "    15167    0.019    0.000    0.044    0.000 {built-in method builtins.sum}\n",
      "    73007    0.019    0.000    0.019    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/tokenize/regexp.py:118(_check_regexp)\n",
      "     1000    0.018    0.000    0.018    0.000 {built-in method posix.stat}\n",
      "    73366    0.016    0.000    0.016    0.000 {method 'pop' of 'list' objects}\n",
      "    57840    0.016    0.000    0.016    0.000 {method 'lower' of 'str' objects}\n",
      "    18960    0.007    0.000    0.007    0.000 {built-in method builtins.min}\n",
      "      500    0.005    0.000    0.005    0.000 {method 'close' of '_io.BufferedReader' objects}\n",
      "     1000    0.004    0.000    0.004    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/compat.py:25(add_py3_data)\n",
      "      500    0.004    0.000    0.012    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:988(__init__)\n",
      "     1000    0.003    0.000    0.036    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/compat.py:39(_decorator)\n",
      "    15667    0.003    0.000    0.003    0.000 {method 'extend' of 'list' objects}\n",
      "        1    0.003    0.003    0.003    0.003 {built-in method _collections._count_elements}\n",
      "      999    0.003    0.000    0.009    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/util.py:217(close)\n",
      "      500    0.002    0.000    0.052    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:323(open)\n",
      "        1    0.002    0.002    0.004    0.004 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/collections/__init__.py:660(update)\n",
      "      500    0.002    0.000    0.006    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:1401(_check_bom)\n",
      "        1    0.002    0.002    0.002    0.002 /var/folders/8v/tw2k9h3n5k5d1stxdsh3q6d00000gn/T/ipykernel_92629/1351017358.py:8(<listcomp>)\n",
      "      500    0.001    0.000    0.002    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/re/__init__.py:272(_compile)\n",
      "        1    0.001    0.001    0.001    0.001 /var/folders/8v/tw2k9h3n5k5d1stxdsh3q6d00000gn/T/ipykernel_92629/1351017358.py:10(<dictcomp>)\n",
      "      500    0.001    0.000    0.002    0.000 <frozen posixpath>:71(join)\n",
      "        1    0.001    0.001   22.453   22.453 /var/folders/8v/tw2k9h3n5k5d1stxdsh3q6d00000gn/T/ipykernel_92629/1351017358.py:7(__init__)\n",
      "      500    0.001    0.000    0.055    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/util.py:202(_open)\n",
      "      500    0.001    0.000    0.008    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/util.py:125(__init__)\n",
      "     1003    0.001    0.000    0.001    0.000 {built-in method _abc._abc_instancecheck}\n",
      "      500    0.001    0.000    0.001    0.000 {method 'sub' of 're.Pattern' objects}\n",
      "      500    0.001    0.000    0.020    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:332(join)\n",
      "      500    0.001    0.000    0.001    0.000 {built-in method _codecs.lookup}\n",
      "        1    0.001    0.001    0.010    0.010 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/tagged.py:99(<listcomp>)\n",
      "      500    0.001    0.000    0.004    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/re/__init__.py:178(sub)\n",
      "        1    0.001    0.001    0.001    0.001 /var/folders/8v/tw2k9h3n5k5d1stxdsh3q6d00000gn/T/ipykernel_92629/1351017358.py:9(<dictcomp>)\n",
      "      500    0.001    0.000    0.003    0.000 <frozen posixpath>:397(abspath)\n",
      "      500    0.001    0.000    0.016    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:302(__init__)\n",
      "        1    0.001    0.001    0.001    0.001 /var/folders/8v/tw2k9h3n5k5d1stxdsh3q6d00000gn/T/ipykernel_92629/1351017358.py:13(<listcomp>)\n",
      "      500    0.001    0.000    0.001    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:1158(__del__)\n",
      "      500    0.001    0.000    0.001    0.000 <frozen posixpath>:389(normpath)\n",
      "      500    0.001    0.000    0.001    0.000 <frozen codecs>:980(getdecoder)\n",
      "      500    0.001    0.000    0.009    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/tagged.py:264(__init__)\n",
      "     1003    0.001    0.000    0.002    0.000 <frozen abc>:117(__instancecheck__)\n",
      "      500    0.001    0.000    0.005    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:1192(close)\n",
      "      500    0.000    0.000    0.001    0.000 <frozen posixpath>:60(isabs)\n",
      "     1000    0.000    0.000    0.001    0.000 <frozen posixpath>:41(_get_sep)\n",
      "      500    0.000    0.000    0.006    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:329(file_size)\n",
      "        1    0.000    0.000    0.021    0.021 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/api.py:195(<listcomp>)\n",
      "      500    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/data.py:1177(closed)\n",
      "      500    0.000    0.000    0.012    0.000 <frozen genericpath>:16(exists)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/zmq/sugar/socket.py:621(send)\n",
      "     2000    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
      "      500    0.000    0.000    0.000    0.000 {built-in method posix._path_normpath}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.array}\n",
      "        2    0.000    0.000   35.664   17.832 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3517(run_code)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/api.py:202(<listcomp>)\n",
      "      500    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/api.py:234(encoding)\n",
      "      500    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/util.py:236(__len__)\n",
      "        1    0.000    0.000    0.021    0.021 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/api.py:172(abspaths)\n",
      "        1    0.000    0.000   35.628   35.628 /var/folders/8v/tw2k9h3n5k5d1stxdsh3q6d00000gn/T/ipykernel_92629/2396163106.py:1(prepare_dataset)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "        6    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/ipykernel/iostream.py:626(write)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/util.py:446(<setcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:225(__init__)\n",
      "    20/19    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:416(__setattr__)\n",
      "        1    0.000    0.000    0.004    0.004 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/collections/__init__.py:587(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/ipykernel/iostream.py:259(schedule)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/util.py:434(concat)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "        1    0.000    0.000    0.031    0.031 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/tagged.py:91(sents)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/codeop.py:120(__call__)\n",
      "        6    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/ipykernel/iostream.py:521(_is_master_process)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/threading.py:1192(is_alive)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/traitlets/traitlets.py:677(__get__)\n",
      "        6    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/ipykernel/iostream.py:548(_schedule_flush)\n",
      "        2    0.000    0.000   35.664   17.832 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._log_api_usage_once}\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/contextlib.py:104(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/threading.py:1125(_wait_for_tstate_lock)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.set_vital}\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/traitlets/traitlets.py:630(get)\n",
      "        1    0.000    0.000    0.031    0.031 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/api.py:408(sents)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/ipykernel/iostream.py:137(_event_pipe)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/sampler.py:129(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/contextlib.py:141(__exit__)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/contextlib.py:299(helper)\n",
      "        4    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/IPython/core/compilerop.py:180(extra_flags)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/numpy/core/_methods.py:47(_sum)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/contextlib.py:132(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/sampler.py:256(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3469(compare)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/util.py:449(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.all}\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py:1255(user_global_ns)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/collections.py:176(__iter__)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/sampler.py:142(num_samples)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:485(check_worker_number_rationality)\n",
      "        2    0.000    0.000    0.000    0.000 /var/folders/8v/tw2k9h3n5k5d1stxdsh3q6d00000gn/T/ipykernel_92629/1351017358.py:40(__len__)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/threading.py:575(is_set)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:392(multiprocessing_context)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _bisect.bisect_right}\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/util.py:384(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/typing.py:2268(cast)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:440(_auto_collation)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/tevfikaytekin/miniforge3/envs/pytorch/lib/python3.11/site-packages/nltk/corpus/reader/api.py:394(_resolve)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x105341090>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "# Create a Profile object\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "# The code you want to profile\n",
    "prepare_dataset()\n",
    "\n",
    "profiler.disable()\n",
    "\n",
    "# Create Stats object\n",
    "stats = pstats.Stats(profiler).sort_stats('time')\n",
    "\n",
    "# Print the statistics\n",
    "stats.print_stats()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9071,  0.0152,  0.6542, -0.3143,  0.8903,  1.1885,  1.0614,  0.0296,\n",
      "         1.2233,  0.1220, -1.0490,  0.2780, -0.2735,  0.0874,  1.3916,  0.3399,\n",
      "         0.8787, -0.8516,  0.5996, -0.4491])\n"
     ]
    }
   ],
   "source": [
    "# Inspect embeddings\n",
    "word_embeddings = model.target_embeddings.weight.data\n",
    "print(word_embeddings[dataset.vocab[\"atlanta\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def find_most_similar(word, word_to_int, int_to_word, embeddings, top_n=5):\n",
    "    # Get the embedding for the given word\n",
    "    word_idx = word_to_int[word]\n",
    "    word_embedding = embeddings[word_idx].reshape(1, -1)\n",
    "    \n",
    "    # Calculate cosine similarity between this word and all other words in the vocabulary\n",
    "    similarities = []\n",
    "    for i in range(len(embeddings)):\n",
    "        other_word_embedding = embeddings[i].reshape(1, -1)\n",
    "        similarity = cosine_similarity(word_embedding, other_word_embedding)[0][0]\n",
    "        similarities.append((i, similarity))\n",
    "    \n",
    "    # Sort by similarity\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Convert indices back to words and filter out the input word\n",
    "    similar_words = [(int_to_word[sim[0]], sim[1]) for sim in similarities if sim[0] != word_idx]\n",
    "    \n",
    "    # Return the top N most similar words, excluding the word itself\n",
    "    return similar_words[:top_n]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'book': [('balance', 0.8909827), ('gaggle', 0.88423204), ('announcement', 0.8836107), ('drummer', 0.88299674), ('chopped', 0.87900347)]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "word = 'book'  # The word you want to find similar words for\n",
    "similar_words = find_most_similar(word, dataset.vocab, dataset.index_to_word, word_embeddings, top_n=5)\n",
    "print(f\"Most similar words to '{word}':\", similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
