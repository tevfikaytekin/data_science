{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from nltk.corpus import brown\n",
    "from  gensim.utils import simple_preprocess\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_words = brown.words()\n",
    "brown_text = \" \".join(brown.words()).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sentences: 57340\n"
     ]
    }
   ],
   "source": [
    "num_sents = len(brown.sents())\n",
    "print(\"number of sentences:\", num_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41239"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(simple_preprocess(brown_text.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'y']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {\"x\":4, \"y\":3}\n",
    "list(a.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Word2VecModel, self).__init__()\n",
    "        self.target_embeddings = nn.Embedding(vocab_size, embedding_dim, sparse=True)\n",
    "        self.context_embeddings = nn.Embedding(vocab_size, embedding_dim, sparse=True)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.target_embeddings.weight.data.uniform_(-1, 1)\n",
    "        self.context_embeddings.weight.data.uniform_(-1, 1)\n",
    "\n",
    "    def forward(self, target_words, context_words, negative_words):\n",
    "        target_embeds = self.target_embeddings(target_words)\n",
    "        context_embeds = self.context_embeddings(context_words)\n",
    "        negative_embeds = self.context_embeddings(negative_words)\n",
    "\n",
    "        positive_score = torch.sum(target_embeds * context_embeds, dim=1)\n",
    "        negative_score = torch.bmm(negative_embeds, target_embeds.unsqueeze(2)).squeeze()\n",
    "\n",
    "        return -torch.mean(torch.log(torch.sigmoid(positive_score)) + torch.sum(torch.log(torch.sigmoid(-negative_score)), dim=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_brown_corpus():\n",
    "    processed_sentences = []\n",
    "    for sentence in brown.sents():\n",
    "        processed_sentence = simple_preprocess(' '.join(sentence), deacc=True)  \n",
    "        processed_sentences.append(processed_sentence)\n",
    "    return processed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch_size=512, window_size=5):\n",
    "    # Example corpus\n",
    "    corpus = preprocess_brown_corpus()\n",
    "    print(\"preprocessed\")\n",
    "    # Hyperparameters\n",
    "    total_negative_samples = 10000\n",
    "\n",
    "    # Prepare dataset and dataloader\n",
    "    dataset = Word2VecSentenceDataset(corpus, window_size)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    print(\"model loaded\")\n",
    "    return dataset, dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(dataset, dataloader, epochs = 10, embedding_dim = 20):\n",
    "\n",
    "     \n",
    "     learning_rate = 0.01\n",
    "\n",
    "     vocab_size = len(dataset.vocab)\n",
    "     model = Word2VecModel(vocab_size, embedding_dim)\n",
    "     \n",
    "     optimizer = optim.SparseAdam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "     # Example training loop\n",
    "     for epoch in range(epochs):\n",
    "          total_loss = 0\n",
    "          for target, context, negatives in tqdm(dataloader):  \n",
    "               model.zero_grad()\n",
    "               loss = model(target, context, negatives)\n",
    "               loss.backward()\n",
    "               optimizer.step()\n",
    "               total_loss += loss.item()\n",
    "               \n",
    "          \n",
    "          print(f\"Epoch {epoch}, Loss: {total_loss}\")\n",
    "\n",
    "     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed\n",
      "model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 57051/4076756 [01:19<1:33:13, 718.66it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Word2VecSentenceDataset\n\u001b[1;32m      3\u001b[0m dataset, dataloader \u001b[38;5;241m=\u001b[39m prepare_dataset(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, window_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 20\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataset, dataloader, epochs, embedding_dim)\u001b[0m\n\u001b[1;32m     18\u001b[0m      loss \u001b[38;5;241m=\u001b[39m model(target, context, negatives)\n\u001b[1;32m     19\u001b[0m      loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 20\u001b[0m      \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m      total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/optim/sparse_adam.py:87\u001b[0m, in \u001b[0;36mSparseAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;66;03m# record the step after step update\u001b[39;00m\n\u001b[1;32m     85\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 87\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse_adam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m                  \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/optim/_functional.py:64\u001b[0m, in \u001b[0;36msparse_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, state_steps, eps, beta1, beta2, lr, maximize)\u001b[0m\n\u001b[1;32m     62\u001b[0m old_exp_avg_values \u001b[38;5;241m=\u001b[39m exp_avg\u001b[38;5;241m.\u001b[39msparse_mask(grad)\u001b[38;5;241m.\u001b[39m_values()\n\u001b[1;32m     63\u001b[0m exp_avg_update_values \u001b[38;5;241m=\u001b[39m grad_values\u001b[38;5;241m.\u001b[39msub(old_exp_avg_values)\u001b[38;5;241m.\u001b[39mmul_(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m---> 64\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmake_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg_update_values\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m old_exp_avg_sq_values \u001b[38;5;241m=\u001b[39m exp_avg_sq\u001b[38;5;241m.\u001b[39msparse_mask(grad)\u001b[38;5;241m.\u001b[39m_values()\n\u001b[1;32m     66\u001b[0m exp_avg_sq_update_values \u001b[38;5;241m=\u001b[39m grad_values\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msub_(old_exp_avg_sq_values)\u001b[38;5;241m.\u001b[39mmul_(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from dataset import Word2VecSentenceDataset\n",
    "\n",
    "dataset, dataloader = prepare_dataset(batch_size=2, window_size=5)\n",
    "model = train(dataset, dataloader, epochs=10, embedding_dim = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], profile_memory=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model = train(dataset, dataloader)\n",
    "print(\"xxxxxxxxxx\")\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "# Create a Profile object\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "# The code you want to profile\n",
    "prepare_dataset()\n",
    "\n",
    "profiler.disable()\n",
    "\n",
    "# Create Stats object\n",
    "stats = pstats.Stats(profiler).sort_stats('time')\n",
    "\n",
    "# Print the statistics\n",
    "stats.print_stats()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3267,  0.7514,  1.2598, -1.1448,  0.9017,  0.9587, -0.5572,  0.1618,\n",
      "        -0.3747,  0.0158, -0.0851,  0.3130, -0.5470, -0.8754,  0.4080, -0.8159,\n",
      "        -0.2363, -0.7520,  1.5831,  1.6928])\n"
     ]
    }
   ],
   "source": [
    "# Inspect embeddings\n",
    "word_embeddings = model.target_embeddings.weight.data\n",
    "print(word_embeddings[dataset.vocab[\"atlanta\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def find_most_similar(word, word_to_int, int_to_word, embeddings, top_n=5):\n",
    "    # Get the embedding for the given word\n",
    "    word_idx = word_to_int[word]\n",
    "    word_embedding = embeddings[word_idx].reshape(1, -1)\n",
    "    \n",
    "    # Calculate cosine similarity between this word and all other words in the vocabulary\n",
    "    similarities = []\n",
    "    for i in range(len(embeddings)):\n",
    "        other_word_embedding = embeddings[i].reshape(1, -1)\n",
    "        similarity = cosine_similarity(word_embedding, other_word_embedding)[0][0]\n",
    "        similarities.append((i, similarity))\n",
    "    \n",
    "    # Sort by similarity\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Convert indices back to words and filter out the input word\n",
    "    similar_words = [(int_to_word[sim[0]], sim[1]) for sim in similarities if sim[0] != word_idx]\n",
    "    \n",
    "    # Return the top N most similar words, excluding the word itself\n",
    "    return similar_words[:top_n]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'novel': [('palaces', 0.94185334), ('relate', 0.9196436), ('significance', 0.9014138), ('pathological', 0.8921088), ('older', 0.88997984)]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "word = 'novel'  # The word you want to find similar words for\n",
    "similar_words = find_most_similar(word, dataset.vocab, dataset.index_to_word, word_embeddings, top_n=5)\n",
    "print(f\"Most similar words to '{word}':\", similar_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
