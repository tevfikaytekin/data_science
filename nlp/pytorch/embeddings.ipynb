{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gensim.downloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### glove-twitter-25\n",
    "\n",
    "Pre-trained glove vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased.\n",
    "\n",
    "The embedding vector size is 25.\n",
    "\n",
    "These embeddings are created with the glove algorithm. For more information:\n",
    "https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors = gensim.downloader.load('glove-twitter-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1193514"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glove_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.69214 , -0.12197 ,  1.0062  ,  0.20488 ,  0.62601 , -0.22483 ,\n",
       "        1.1476  ,  0.76476 ,  1.2868  , -0.35359 ,  0.3194  ,  1.3029  ,\n",
       "       -1.918   , -0.38725 ,  0.17671 ,  0.53027 ,  0.74713 ,  0.19896 ,\n",
       "       -0.37732 ,  0.098764, -1.3672  , -0.34753 , -1.9951  , -0.13393 ,\n",
       "       -0.51779 ], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors['novel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dog', 0.9590820074081421),\n",
       " ('monkey', 0.9203579425811768),\n",
       " ('bear', 0.9143137335777283),\n",
       " ('pet', 0.9108031392097473),\n",
       " ('girl', 0.8880630731582642),\n",
       " ('horse', 0.8872725963592529),\n",
       " ('kitty', 0.8870542049407959),\n",
       " ('puppy', 0.8867696523666382),\n",
       " ('hot', 0.886525571346283),\n",
       " ('lady', 0.8845519423484802)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('capital', 0.9298303127288818),\n",
       " ('community', 0.8911738395690918),\n",
       " ('central', 0.8903511762619019),\n",
       " ('york', 0.8817622065544128),\n",
       " ('uk', 0.8771563172340393),\n",
       " ('social', 0.8731585144996643),\n",
       " ('campus', 0.8682253360748291),\n",
       " ('rural', 0.8651514649391174),\n",
       " ('general', 0.8649173974990845),\n",
       " ('union', 0.8621615767478943)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar('local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d4d8c20ad3437fbcb9b449448fa213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between the two sentences: 0.7752428650856018\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# Example sentences\n",
    "sentence1 = \"natural language processing is a subfield of artificial intelligence\"\n",
    "sentence2 = \"word embeddings semantic relationships between words\"\n",
    "\n",
    "# Tokenize and encode sentences\n",
    "tokens1 = tokenizer(sentence1, return_tensors='pt')\n",
    "tokens2 = tokenizer(sentence2, return_tensors='pt')\n",
    "\n",
    "# Get BERT embeddings for sentences\n",
    "with torch.no_grad():\n",
    "    outputs1 = model(**tokens1)\n",
    "    outputs2 = model(**tokens2)\n",
    "\n",
    "# Extract embeddings from BERT outputs\n",
    "embedding1 = outputs1['last_hidden_state'][:, 0, :].numpy()\n",
    "embedding2 = outputs2['last_hidden_state'][:, 0, :].numpy()\n",
    "\n",
    "# Calculate cosine similarity between embeddings\n",
    "similarity_score = cosine_similarity(embedding1, embedding2)[0][0]\n",
    "\n",
    "# Print results\n",
    "print(f\"Similarity between the two sentences: {similarity_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 3019, 2653, 6364, 2003, 1037, 4942, 3790, 1997, 7976, 4454,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens1['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
