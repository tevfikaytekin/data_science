{"cells":[{"cell_type":"markdown","metadata":{"id":"RMh0SluV9GuG"},"source":["### Rating Prediction using Machine Learning\n","\n","We will extract features and build a model for ratings prediction."]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"3f06NDcR9YQb"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E5bNlV4z9GuJ"},"outputs":[],"source":["from datetime import datetime\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from lightgbm import LGBMRanker, LGBMRegressor, LGBMClassifier\n","from tqdm import tqdm\n","from xgboost import XGBRanker\n","from sklearn.model_selection import cross_val_score, train_test_split\n","from sklearn.metrics import mean_absolute_error\n","\n","\n","ratings = pd.read_csv(\"/content/drive/My Drive/datasets/ml-latest-small/ratings.csv\", sep=\",\")\n","\n","ratings.head()"]},{"cell_type":"markdown","source":["We will only use the ratings dataset to extract the features. Since we are not using any other content information such as movie plot, genres, directors, etc., this might look like rather limited, however, the results as we will show below are not bad.\n","\n","Below are some general information about these features."],"metadata":{"id":"WBKDh_y7B3cV"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"OBHxv25h9GuL"},"outputs":[],"source":["ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s')\n","ratings.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5glnFl8b9GuM"},"outputs":[],"source":["ratings.rating.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QI2IqkdB9GuM"},"outputs":[],"source":["ratings['timestamp'].dt.day_name().value_counts()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E1VTB5oq9GuM"},"outputs":[],"source":["ratings.timestamp.dt.hour.value_counts()"]},{"cell_type":"markdown","source":["Now, we will extract features for each user and item and prepare a dataset for model fitting."],"metadata":{"id":"_K87KrGZCsei"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"MWyDmR259GuN"},"outputs":[],"source":["# Copied from bturan19's kaggle nb.\n","def get_feature_by_user(df):\n","    res = list()\n","    for i, v in tqdm(df.groupby('userId')):\n","        res.append(\n","            (\n","                i,\n","                len(v['movieId']),\n","                (v['rating'] == 5).sum(),\n","                (v['rating'] == 4).sum(),\n","                (v['rating'] == 3).sum(),\n","                (v['rating'] == 2).sum(),\n","                (v['rating'] == 1).sum(),\n","                (v['timestamp'].dt.dayofweek == 0).sum(),\n","                (v['timestamp'].dt.dayofweek == 1).sum(),\n","                (v['timestamp'].dt.dayofweek == 2).sum(),\n","                (v['timestamp'].dt.dayofweek == 3).sum(),\n","                (v['timestamp'].dt.dayofweek == 4).sum(),\n","                (v['timestamp'].dt.dayofweek == 5).sum(),\n","                (v['timestamp'].dt.dayofweek == 6).sum(),\n","                (v['timestamp'].dt.hour > 17).sum()\n","\n","            )\n","        )\n","\n","    res = pd.DataFrame(\n","        res,\n","        columns=[\n","            'userId', 'reviewed_products', '5_star_ratings_gave', '4_star_ratings_gave',\n","            '3_star_ratings_gave', '2_star_ratings_gave', '1_star_ratings_gave',\n","            'monday_review_count_user', 'tuesday_review_count_user', 'wednesday_review_count_user', 'thursday_review_count_user',\n","            'friday_review_count_user', 'saturday_review_count_user', 'sunday_review_count_user','evening_reviews_by_user'\n","        ])\n","    return res"]},{"cell_type":"code","source":["user_features = get_feature_by_user(ratings)"],"metadata":{"id":"QhbfhiMYAYlp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["user_features.head()"],"metadata":{"id":"nGGY8s_wAbd2"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"loDjssi59GuN"},"outputs":[],"source":["# Copied from bturan19's kaggle nb.\n","\n","def get_feature_by_product(df):\n","    res = list()\n","    for i, v in tqdm(df.groupby('movieId')):\n","        res.append(\n","            (\n","                i,\n","                len(v['userId']),\n","                (v['rating'] == 5).sum(),\n","                (v['rating'] == 4).sum(),\n","                (v['rating'] == 3).sum(),\n","                (v['rating'] == 2).sum(),\n","                (v['rating'] == 1).sum(),\n","                (v['timestamp'].dt.dayofweek == 0).sum(),\n","                (v['timestamp'].dt.dayofweek == 1).sum(),\n","                (v['timestamp'].dt.dayofweek == 2).sum(),\n","                (v['timestamp'].dt.dayofweek == 3).sum(),\n","                (v['timestamp'].dt.dayofweek == 4).sum(),\n","                (v['timestamp'].dt.dayofweek == 5).sum(),\n","                (v['timestamp'].dt.dayofweek == 6).sum(),\n","                (v['timestamp'].dt.hour > 17).sum()\n","            )\n","        )\n","\n","    res = pd.DataFrame(\n","        res,\n","        columns=[\n","            'movieId', 'user_count', '1_star_ratings_recieved', '2_star_ratings_recieved',\n","            '3_star_ratings_recieved', '4_star_ratings_recieved', '5_star_ratings_recieved',\n","            'monday_review_count_item', 'tuesday_review_count_item', 'wednesday_review_count_item', 'thursday_review_count_item',\n","            'friday_review_count_item', 'saturday_review_count_item', 'sunday_review_count_item','evening_reviews_by_movie'\n","        ])\n","    return res"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N_7zABtX9GuO"},"outputs":[],"source":["movie_features = get_feature_by_product(ratings)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9sLLNfgX9GuP"},"outputs":[],"source":["movie_features.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a_OsT09y9GuP"},"outputs":[],"source":["merged = pd.merge(ratings, user_features, on=['userId'])\n","merged = pd.merge(merged, movie_features, on=['movieId'])\n","merged.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pD5v5ASE9GuP"},"outputs":[],"source":["y = merged.rating\n","merged = merged.drop(columns=[\"userId\",\"movieId\",\"rating\",\"timestamp\"])\n","merged.head()"]},{"cell_type":"markdown","source":["We will use LGBM which is a fast and easy to use gradient boosting framework."],"metadata":{"id":"nPqCUkYzDHN1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kgcZU3lX9GuP"},"outputs":[],"source":["model = LGBMRegressor()\n","cross_val_score(model,merged,y)"]},{"cell_type":"markdown","metadata":{"id":"CiFBt7Sp9GuP"},"source":["These results are very good, however, we did not pay attention not to leak data from test set. Below is a better approach."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8YuyEiPu9GuQ"},"outputs":[],"source":["ratings_train, ratings_test = train_test_split(ratings, test_size=5000)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AmvJgwAB9GuQ"},"outputs":[],"source":["user_features = get_feature_by_user(ratings_train)\n","movie_features = get_feature_by_product(ratings_train)\n","merged = pd.merge(ratings_train, user_features, on=['userId'])\n","merged = pd.merge(merged, movie_features, on=['movieId'])\n","merged.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sYj_m5pB9GuQ"},"outputs":[],"source":["y = merged.rating\n","merged = merged.drop(columns=[\"userId\",\"movieId\",\"rating\",\"timestamp\"])\n","merged.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"94WJ07xV9GuQ"},"outputs":[],"source":["model = LGBMRegressor()\n","model.fit(merged, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OdzLCbiZ9GuQ"},"outputs":[],"source":["user_features = get_feature_by_user(ratings_test)\n","movie_features = get_feature_by_product(ratings_test)\n","merged = pd.merge(ratings_test, user_features, on=['userId'])\n","merged = pd.merge(merged, movie_features, on=['movieId'])\n","merged.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oLn8jmnH9GuQ"},"outputs":[],"source":["y = merged.rating\n","merged = merged.drop(columns=[\"userId\",\"movieId\",\"rating\",\"timestamp\"])\n","merged.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8s_7EFY89GuQ"},"outputs":[],"source":["preds = model.predict(merged)"]},{"cell_type":"code","source":["preds"],"metadata":{"id":"1XXsI5WuCjf3"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4bim6SAJ9GuQ"},"outputs":[],"source":["mean_absolute_error(y, preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CCLctUTH9GuR"},"outputs":[],"source":["imps = model.feature_importances_\n","sorted_idx = np.argsort(imps)[::-1]\n","sorted_vals = np.sort(imps)[::-1]\n","\n","d = {\"feature_name\":merged.columns[sorted_idx], \"value\":sorted_vals}\n","imp_df = pd.DataFrame(d)\n","imp_df[:20]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6EyUljqa9GuR"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"pytorch","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}