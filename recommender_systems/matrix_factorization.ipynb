{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["\u003ca href=\"https://colab.research.google.com/github/tevfikaytekin/data_science/blob/master/recommender_systems/matrix_factorization.ipynb\" target=\"_parent\"\u003e\u003cimg src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/\u003e\u003c/a\u003e"]},{"cell_type":"markdown","metadata":{"id":"dgs5IIoUSn9l"},"source":["# Matrix Factorization\n","(by Tevfik Aytekin)\n","\n","Matrix factorizarion is one of the state-of-the-art techniques used in recommender systems. Below you can find several different implementations.\n","\n","Over the years many variations of matrix factorization have been proposed. The following formulation is one of the simplest but constitues the foundation of many others. It can be extended it various ways, see for example [Advances in Collaborative Filtering](https://link.springer.com/chapter/10.1007/978-1-4899-7637-6_3).\n","\n","Cost Function:\n","$$\n","J(\\Theta) =  \\sum_{u,i \\in K} (r_{ui} - q^T_ip_u)^2 + \\lambda(||q_i||^2+||p_u||^2)\n","$$\n","\n","where\n","\n","- $r_{ui}$ is the rating of user $u$ for item $i$.\n","- $K$ is the set of $(u,i)$ pairs for which $r_{ui}$ is known.\n","- $q_i$, $p_u$ are latent factor vectors for items and users, respectively.\n","- $\\lambda$ is the regularization parameter.\n","\n","And the optimization objective:\n","\n","$$\n","\\min_{p*,q*} \\sum_{u,i \\in K} (r_{ui} - q^T_ip_u)^2 + \\lambda(||q_i||^2+||p_u||^2)\n","$$\n","\n","Typically the optimization done with gradient descent. To apply it we need to first find the partial derivative of the cost function with respect to latent variables which we will denote as $q_{fi}$ and $p_{fu}$. We can find the partial derivative as:\n","\n","$$\n","\\frac{\\partial J(\\Theta)}{\\partial p_{ku}}=-\\sum_{i \\in I_u}2(r_{ui} - q^T_ip_u)q_{ki} + 2\\lambda p_{ku}\n","$$\n","\n","For **stochastic gradient descent** the update rule for the the $p_u$ vector for a single training example is:\n","\n","$$\n","p_u = p_u + \\alpha ((r_{ui} - q^T_ip_u)q_{i} - \\lambda p_{u})\n","$$\n","\n","similarly for $q_i$ vector we have:\n","\n","$$\n","q_i = q_i + \\alpha ((r_{ui} - q^T_ip_u)p_{u} - \\lambda q_{u})\n","$$\n","\n","For **batch gradient descent** the update rule for the the $p_u$ vector for all preferences where user $u$ appears:\n","\n","$$\n","p_u = p_u + \\alpha (\\sum_{i \\in I_u}(r_{ui} - q^T_ip_u)q_{i} - \\lambda p_{u})\n","$$\n","\n","similarly for $q_i$ vector we have:\n","\n","$$\n","q_i = q_i + \\alpha (\\sum_{u \\in U_i} (r_{ui} - q^T_ip_u)p_{u} - \\lambda q_{u})\n","$$\n","\n","In the above equations $I_u$ is the set of items rated by user $u$ and $U_i$ is the set of users who rated item $i$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"84apIe07Sn9q"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","from scipy.sparse import csr_matrix\n","import copy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uOefuRr5IKPO"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"xzo9HTNYSn9r"},"source":["# Movielens dataset\n","\n","We will use the smallest Movielens 100k Dataset which includes 100k preferences. A preference is a triple (user, item, rating). You can download this data set from\n","[https://grouplens.org/datasets/movielens/](https://grouplens.org/datasets/movielens/)\n","\n","Note the sparsity of the dataset which shows that most of the user/item matrix is empty. This is a typical property of the datasets in this domain."]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1763487257127,"user":{"displayName":"Tevfik Aytekin","userId":"03705756795675396046"},"user_tz":-180},"id":"JvZEZ2KFSn9r","outputId":"0fc95636-c437-43a5-e51b-29660cdc76e7"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"prefs"},"text/html":["\n","  \u003cdiv id=\"df-f0aa4ce7-a744-4bd4-b3ff-130e94731c21\" class=\"colab-df-container\"\u003e\n","    \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003euserId\u003c/th\u003e\n","      \u003cth\u003emovieId\u003c/th\u003e\n","      \u003cth\u003erating\u003c/th\u003e\n","      \u003cth\u003etimestamp\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e4.0\u003c/td\u003e\n","      \u003ctd\u003e964982703\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e4.0\u003c/td\u003e\n","      \u003ctd\u003e964981247\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003e4.0\u003c/td\u003e\n","      \u003ctd\u003e964982224\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e47\u003c/td\u003e\n","      \u003ctd\u003e5.0\u003c/td\u003e\n","      \u003ctd\u003e964983815\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e50\u003c/td\u003e\n","      \u003ctd\u003e5.0\u003c/td\u003e\n","      \u003ctd\u003e964982931\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","    \u003cdiv class=\"colab-df-buttons\"\u003e\n","\n","  \u003cdiv class=\"colab-df-container\"\u003e\n","    \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0aa4ce7-a744-4bd4-b3ff-130e94731c21')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\"\u003e\n","\n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\"\u003e\n","    \u003cpath d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/\u003e\n","  \u003c/svg\u003e\n","    \u003c/button\u003e\n","\n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","    \u003cscript\u003e\n","      const buttonEl =\n","        document.querySelector('#df-f0aa4ce7-a744-4bd4-b3ff-130e94731c21 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f0aa4ce7-a744-4bd4-b3ff-130e94731c21');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    \u003c/script\u003e\n","  \u003c/div\u003e\n","\n","\n","    \u003cdiv id=\"df-da39ecad-46a5-4384-a1a4-2d15abc75984\"\u003e\n","      \u003cbutton class=\"colab-df-quickchart\" onclick=\"quickchart('df-da39ecad-46a5-4384-a1a4-2d15abc75984')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\"\u003e\n","\n","\u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\"\u003e\n","    \u003cg\u003e\n","        \u003cpath d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/\u003e\n","    \u003c/g\u003e\n","\u003c/svg\u003e\n","      \u003c/button\u003e\n","\n","\u003cstyle\u003e\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","\u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() =\u003e {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-da39ecad-46a5-4384-a1a4-2d15abc75984 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n"],"text/plain":["   userId  movieId  rating  timestamp\n","0       1        1     4.0  964982703\n","1       1        3     4.0  964981247\n","2       1        6     4.0  964982224\n","3       1       47     5.0  964983815\n","4       1       50     5.0  964982931"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["prefs = pd.read_csv(\"/content/drive/My Drive/datasets/ml-latest-small/ratings.csv\", sep=\",\")\n","\n","prefs.head()"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1763486869884,"user":{"displayName":"Tevfik Aytekin","userId":"03705756795675396046"},"user_tz":-180},"id":"KNUNaoQSSn9s","outputId":"8e81796a-6730-46f3-8bb1-605247cc1cf2","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of users: 610\n","Number of items: 9724\n","Number of preferences: 100836\n","Sparsity: 0.016999683055613623\n"]}],"source":["n_users = prefs.iloc[:,0].unique().size\n","n_items = prefs.iloc[:,1].unique().size\n","n_prefs = prefs.iloc[:,1].size\n","users = prefs.iloc[:,0].unique()\n","items = prefs.iloc[:,1].unique()\n","\n","print(\"Number of users:\",n_users)\n","print(\"Number of items:\",n_items)\n","print(\"Number of preferences:\",n_prefs)\n","print(\"Sparsity:\",n_prefs/(n_users*n_items))"]},{"cell_type":"markdown","metadata":{"id":"9A6dD4keSn9t"},"source":["### Error Function\n","\n","Error is calculated by predicting the rating of a user and an item in the test set using the factor representations of users and items."]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1763487023692,"user":{"displayName":"Tevfik Aytekin","userId":"03705756795675396046"},"user_tz":-180},"id":"R6xzCHN4Sn9t"},"outputs":[],"source":["def calc_error(X, u_factors, i_factors):\n","    error = 0\n","    for i in range(X.shape[0]):\n","        u_idx = X.iloc[i,0]\n","        i_idx = X.iloc[i,1]\n","        error += np.abs(X.iloc[i,2] - np.dot(u_factors[u_idx].T, i_factors[i_idx]))\n","    return error/X.shape[0]\n"]},{"cell_type":"markdown","metadata":{"id":"AE8UpWc1Sn9u"},"source":["### Random Predictor Error\n","\n","**Exercise**: What is the expected error of a random predictor given that the actual ratings are uniformly distributed between 1 and 5?\n","\n","Below is a function for calculating this error experimentally."]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1763487105600,"user":{"displayName":"Tevfik Aytekin","userId":"03705756795675396046"},"user_tz":-180},"id":"NX4-hb8vSn9v"},"outputs":[],"source":["def random_predictor_error(X):\n","    error = 0\n","    for i in range(X.shape[0]):\n","        u_idx = X.iloc[i,0]\n","        i_idx = X.iloc[i,1]\n","        error += np.abs(X.iloc[i,2] - np.random.randint(1,6))\n","    return error/X.shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G04__7fiDCHz"},"outputs":[],"source":["print(\"Random predictor error: \", random_predictor_error(prefs))"]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":4686,"status":"ok","timestamp":1763488017226,"user":{"displayName":"Tevfik Aytekin","userId":"03705756795675396046"},"user_tz":-180},"id":"bvgyC1VJSn9v"},"outputs":[],"source":["# initialize factor matrices\n","n_factors = 5\n","item_factors = {}\n","user_factors = {}\n","for r in range(n_prefs):\n","    user_factors[prefs.iloc[r,0]] = np.random.rand(n_factors,1) - 0.5\n","    item_factors[prefs.iloc[r,1]] = np.random.rand(n_factors,1) - 0.5"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6951,"status":"ok","timestamp":1763488063917,"user":{"displayName":"Tevfik Aytekin","userId":"03705756795675396046"},"user_tz":-180},"id":"qAVXvpFuSn9w","outputId":"e4f7811e-0a9a-4f43-b870-af3006bfd532"},"outputs":[{"name":"stdout","output_type":"stream","text":["Initial error:  [[3.50154327]]\n"]}],"source":["print(\"Initial error: \", calc_error(prefs, user_factors, item_factors))"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1763487775411,"user":{"displayName":"Tevfik Aytekin","userId":"03705756795675396046"},"user_tz":-180},"id":"PaBjyPnJD3EU","outputId":"7085f150-4105-4df3-8fcf-020edaaf80f2"},"outputs":[{"data":{"text/plain":["array([[ 0.39515997],\n","       [ 0.19959287],\n","       [-0.14135778],\n","       [-0.18516197],\n","       [-0.35546027]])"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["item_factors[10]"]},{"cell_type":"markdown","metadata":{"id":"HhCmDB3TSn9x"},"source":["### Stochastic Gradient Descent\n","\n","Following is the stochastic gradient algorithm which is popularized by [Simon Funk](https://sifter.org/simon/journal/20061211.html)"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":101381,"status":"ok","timestamp":1763488873520,"user":{"displayName":"Tevfik Aytekin","userId":"03705756795675396046"},"user_tz":-180},"id":"_km686P-Sn9x","outputId":"f3c5fc24-c356-4bee-f679-a9feba7cfb5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Initial error:  [[3.50035992]]\n","Iteration  0\n","Train error:  [[1.01392182]]\n","Test error:  [[1.1059455]]\n","Iteration  1\n","Train error:  [[0.79767106]]\n","Test error:  [[0.9115756]]\n","Iteration  2\n","Train error:  [[0.73417548]]\n","Test error:  [[0.86247059]]\n","Iteration  3\n","Train error:  [[0.70217316]]\n","Test error:  [[0.8469007]]\n","Iteration  4\n","Train error:  [[0.68061858]]\n","Test error:  [[0.82954458]]\n"]}],"source":["n_factors = 5\n","item_factors = {}\n","user_factors = {}\n","for r in range(n_prefs):\n","    user_factors[prefs.iloc[r,0]] = np.random.rand(n_factors,1) - 0.5\n","    item_factors[prefs.iloc[r,1]] = np.random.rand(n_factors,1) - 0.5\n","\n","X_train, X_test = train_test_split(prefs, test_size=0.1)\n","\n","# Stochastic Gradient descent\n","alpha = 0.03\n","my_lambda = 0.1\n","n_iters = 5\n","\n","print(\"Initial error: \", calc_error(X_train, user_factors, item_factors))\n","\n","for t in range(n_iters):\n","    #q = 10\n","    #ux = prefs.iloc[q,0]; ix = prefs.iloc[q,1]\n","    #print(\"user factor: \",user_factors[ux],\"item factor: \", item_factors[ix])\n","    #print(\"actual rating: \", prefs.iloc[q,2], \"predicted rating: \", np.dot(user_factors[ux].T,item_factors[ix]))\n","    X_train = shuffle(X_train)\n","    for r in range(X_train.shape[0]):\n","        u = X_train.iloc[r,0]\n","        i = X_train.iloc[r,1]\n","        error = X_train.iloc[r,2] - np.dot(user_factors[u].T, item_factors[i])[0,0]\n","        user_factors[u] = user_factors[u] + alpha*(error*item_factors[i] - my_lambda*user_factors[u])\n","        item_factors[i] = item_factors[i] + alpha*(error*user_factors[u] - my_lambda*item_factors[i])\n","\n","\n","    print(\"Iteration \", t)\n","    print(\"Train error: \", calc_error(X_train, user_factors, item_factors))\n","    print(\"Test error: \", calc_error(X_test, user_factors, item_factors))\n"]},{"cell_type":"markdown","metadata":{"id":"NXo20Bw8etw8"},"source":["### How to make a prediction?\n","Once the user and item factors are learned you can make a prediction for any user and item pair."]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54,"status":"ok","timestamp":1763489272516,"user":{"displayName":"Tevfik Aytekin","userId":"03705756795675396046"},"user_tz":-180},"id":"icHcr58-etw8","outputId":"1bf2aa9b-4e65-4747-8351-5b1c0dd449c8"},"outputs":[{"data":{"text/plain":["array([[-0.11030594],\n","       [-1.06399529],\n","       [-0.25440632],\n","       [-0.76061738],\n","       [-0.85654756]])"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["item_factors[10]"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":92,"status":"ok","timestamp":1763489284245,"user":{"displayName":"Tevfik Aytekin","userId":"03705756795675396046"},"user_tz":-180},"id":"AiSJslsTetw9","outputId":"9e050ace-3d14-4a1f-d1db-cee852ed987a"},"outputs":[{"data":{"text/plain":["array([[-0.0932746 ],\n","       [-1.78955132],\n","       [-0.53572441],\n","       [-0.81697482],\n","       [-1.11421156]])"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["user_factors[100]"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":83,"status":"ok","timestamp":1763489287180,"user":{"displayName":"Tevfik Aytekin","userId":"03705756795675396046"},"user_tz":-180},"id":"Z7QhXG-fetw-","outputId":"8bf5d958-f7c3-4ea4-fca6-827f57162300"},"outputs":[{"data":{"text/plain":["array([[3.45704114]])"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["np.dot(user_factors[10].T, item_factors[50])"]},{"cell_type":"markdown","metadata":{"id":"dgGw4j4GSn9y"},"source":["### Batch Gradient Descent\n","If you run the code below you will see that both training and test errors decrease very slowly. Eventually there will be convergence but compared to stochastic version it will be very slow. It is a good example to show the speed advantage of stochastic gradient descent."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"MdUJbtKBSn9y"},"outputs":[{"name":"stdout","output_type":"stream","text":["Iteration  0\n","Train error:  [[3.48659416]]\n","Test error:  [[3.50862603]]\n","Iteration  1\n","Train error:  [[3.47137386]]\n","Test error:  [[3.50815221]]\n","Iteration  2\n","Train error:  [[3.45429921]]\n","Test error:  [[3.50620902]]\n","Iteration  3\n","Train error:  [[3.43306065]]\n","Test error:  [[3.50127552]]\n","Iteration  4\n","Train error:  [[3.40422149]]\n","Test error:  [[3.49055979]]\n","Iteration  5\n","Train error:  [[3.3621963]]\n","Test error:  [[3.46889578]]\n","Iteration  6\n","Train error:  [[3.29756488]]\n","Test error:  [[3.42689293]]\n","Iteration  7\n","Train error:  [[3.19446947]]\n","Test error:  [[3.34822394]]\n","Iteration  8\n","Train error:  [[3.02789141]]\n","Test error:  [[3.20670607]]\n","Iteration  9\n","Train error:  [[2.76466761]]\n","Test error:  [[2.96773162]]\n","Iteration  10\n","Train error:  [[2.37861468]]\n","Test error:  [[2.60434596]]\n","Iteration  11\n","Train error:  [[1.8885689]]\n","Test error:  [[2.13138292]]\n","Iteration  12\n","Train error:  [[1.39141547]]\n","Test error:  [[1.6455214]]\n","Iteration  13\n","Train error:  [[1.01426397]]\n","Test error:  [[1.27328515]]\n","Iteration  14\n","Train error:  [[0.79782725]]\n","Test error:  [[1.05620825]]\n","Iteration  15\n","Train error:  [[0.69356444]]\n","Test error:  [[0.95001498]]\n","Iteration  16\n","Train error:  [[0.64507463]]\n","Test error:  [[0.89968083]]\n","Iteration  17\n","Train error:  [[0.6216141]]\n","Test error:  [[0.87468131]]\n","Iteration  18\n","Train error:  [[0.60929823]]\n","Test error:  [[0.86089956]]\n","Iteration  19\n","Train error:  [[0.60204664]]\n","Test error:  [[0.85251955]]\n","Iteration  20\n","Train error:  [[0.59725573]]\n","Test error:  [[0.84680251]]\n","Iteration  21\n","Train error:  [[0.59370652]]\n","Test error:  [[0.84250315]]\n","Iteration  22\n","Train error:  [[0.59085294]]\n","Test error:  [[0.83902076]]\n","Iteration  23\n","Train error:  [[0.58841745]]\n","Test error:  [[0.8360287]]\n","Iteration  24\n","Train error:  [[0.58626446]]\n","Test error:  [[0.83335962]]\n","Iteration  25\n","Train error:  [[0.5843164]]\n","Test error:  [[0.83093604]]\n","Iteration  26\n","Train error:  [[0.58253224]]\n","Test error:  [[0.82871293]]\n","Iteration  27\n","Train error:  [[0.58087916]]\n","Test error:  [[0.82664842]]\n","Iteration  28\n","Train error:  [[0.57933708]]\n","Test error:  [[0.82471984]]\n","Iteration  29\n","Train error:  [[0.57789451]]\n","Test error:  [[0.82289931]]\n","Iteration  30\n","Train error:  [[0.57653923]]\n","Test error:  [[0.82117854]]\n","Iteration  31\n","Train error:  [[0.57526171]]\n","Test error:  [[0.81955291]]\n","Iteration  32\n","Train error:  [[0.57405494]]\n","Test error:  [[0.81800382]]\n","Iteration  33\n","Train error:  [[0.5729115]]\n","Test error:  [[0.81652046]]\n","Iteration  34\n","Train error:  [[0.57182581]]\n","Test error:  [[0.81510748]]\n","Iteration  35\n","Train error:  [[0.57079263]]\n","Test error:  [[0.81376387]]\n","Iteration  36\n","Train error:  [[0.56980794]]\n","Test error:  [[0.81247846]]\n","Iteration  37\n","Train error:  [[0.56886871]]\n","Test error:  [[0.81124974]]\n","Iteration  38\n","Train error:  [[0.56797092]]\n","Test error:  [[0.81007292]]\n","Iteration  39\n","Train error:  [[0.56711189]]\n","Test error:  [[0.80894005]]\n","Iteration  40\n","Train error:  [[0.5662887]]\n","Test error:  [[0.80784957]]\n","Iteration  41\n","Train error:  [[0.56549832]]\n","Test error:  [[0.80680902]]\n","Iteration  42\n","Train error:  [[0.56473838]]\n","Test error:  [[0.80580478]]\n","Iteration  43\n","Train error:  [[0.56400642]]\n","Test error:  [[0.80483507]]\n","Iteration  44\n","Train error:  [[0.56329971]]\n","Test error:  [[0.80389342]]\n","Iteration  45\n","Train error:  [[0.56261642]]\n","Test error:  [[0.8029839]]\n","Iteration  46\n","Train error:  [[0.56195526]]\n","Test error:  [[0.80210597]]\n","Iteration  47\n","Train error:  [[0.56131376]]\n","Test error:  [[0.80126178]]\n","Iteration  48\n","Train error:  [[0.56069086]]\n","Test error:  [[0.80044593]]\n","Iteration  49\n","Train error:  [[0.56008637]]\n","Test error:  [[0.79965455]]\n","Iteration  50\n","Train error:  [[0.55950036]]\n","Test error:  [[0.79888994]]\n","Iteration  51\n","Train error:  [[0.5589316]]\n","Test error:  [[0.79814982]]\n","Iteration  52\n","Train error:  [[0.55837904]]\n","Test error:  [[0.79743513]]\n","Iteration  53\n","Train error:  [[0.55784088]]\n","Test error:  [[0.79674306]]\n","Iteration  54\n","Train error:  [[0.55731595]]\n","Test error:  [[0.79606846]]\n","Iteration  55\n","Train error:  [[0.55680462]]\n","Test error:  [[0.79541032]]\n","Iteration  56\n","Train error:  [[0.55630592]]\n","Test error:  [[0.79477618]]\n","Iteration  57\n","Train error:  [[0.55581878]]\n","Test error:  [[0.79415805]]\n","Iteration  58\n","Train error:  [[0.5553426]]\n","Test error:  [[0.79355793]]\n","Iteration  59\n","Train error:  [[0.55487688]]\n","Test error:  [[0.79297294]]\n","Iteration  60\n","Train error:  [[0.55442166]]\n","Test error:  [[0.79240372]]\n","Iteration  61\n","Train error:  [[0.55397553]]\n","Test error:  [[0.79184939]]\n","Iteration  62\n","Train error:  [[0.55353772]]\n","Test error:  [[0.79131141]]\n","Iteration  63\n","Train error:  [[0.55310787]]\n","Test error:  [[0.79078665]]\n","Iteration  64\n","Train error:  [[0.55268605]]\n","Test error:  [[0.7902729]]\n","Iteration  65\n","Train error:  [[0.55227203]]\n","Test error:  [[0.78977078]]\n","Iteration  66\n","Train error:  [[0.55186559]]\n","Test error:  [[0.78928233]]\n","Iteration  67\n","Train error:  [[0.55146589]]\n","Test error:  [[0.78880601]]\n","Iteration  68\n","Train error:  [[0.55107302]]\n","Test error:  [[0.7883441]]\n","Iteration  69\n","Train error:  [[0.55068626]]\n","Test error:  [[0.78789751]]\n","Iteration  70\n","Train error:  [[0.55030491]]\n","Test error:  [[0.78746373]]\n","Iteration  71\n","Train error:  [[0.54992901]]\n","Test error:  [[0.78703922]]\n","Iteration  72\n","Train error:  [[0.54955854]]\n","Test error:  [[0.78662175]]\n","Iteration  73\n","Train error:  [[0.54919353]]\n","Test error:  [[0.78621421]]\n","Iteration  74\n","Train error:  [[0.54883361]]\n","Test error:  [[0.78581656]]\n","Iteration  75\n","Train error:  [[0.54847806]]\n","Test error:  [[0.78542799]]\n","Iteration  76\n","Train error:  [[0.54812711]]\n","Test error:  [[0.78505012]]\n","Iteration  77\n","Train error:  [[0.54778046]]\n","Test error:  [[0.78467984]]\n","Iteration  78\n","Train error:  [[0.54743785]]\n","Test error:  [[0.78431695]]\n","Iteration  79\n","Train error:  [[0.5470993]]\n","Test error:  [[0.78395991]]\n","Iteration  80\n","Train error:  [[0.54676454]]\n","Test error:  [[0.78360899]]\n","Iteration  81\n","Train error:  [[0.54643369]]\n","Test error:  [[0.78326626]]\n","Iteration  82\n","Train error:  [[0.54610655]]\n","Test error:  [[0.78292952]]\n","Iteration  83\n","Train error:  [[0.54578266]]\n","Test error:  [[0.78259907]]\n","Iteration  84\n","Train error:  [[0.54546201]]\n","Test error:  [[0.78227545]]\n","Iteration  85\n","Train error:  [[0.54514438]]\n","Test error:  [[0.78195675]]\n","Iteration  86\n","Train error:  [[0.5448297]]\n","Test error:  [[0.78164137]]\n","Iteration  87\n","Train error:  [[0.54451786]]\n","Test error:  [[0.78133009]]\n","Iteration  88\n","Train error:  [[0.54420854]]\n","Test error:  [[0.78102507]]\n","Iteration  89\n","Train error:  [[0.54390182]]\n","Test error:  [[0.78072591]]\n","Iteration  90\n","Train error:  [[0.54359782]]\n","Test error:  [[0.78043181]]\n","Iteration  91\n","Train error:  [[0.54329602]]\n","Test error:  [[0.78014147]]\n","Iteration  92\n","Train error:  [[0.54299639]]\n","Test error:  [[0.77985471]]\n","Iteration  93\n","Train error:  [[0.54269899]]\n","Test error:  [[0.7795743]]\n","Iteration  94\n","Train error:  [[0.54240385]]\n","Test error:  [[0.77930144]]\n","Iteration  95\n","Train error:  [[0.54211099]]\n","Test error:  [[0.77903268]]\n","Iteration  96\n","Train error:  [[0.54182007]]\n","Test error:  [[0.77876676]]\n","Iteration  97\n","Train error:  [[0.54153114]]\n","Test error:  [[0.77850365]]\n","Iteration  98\n","Train error:  [[0.54124434]]\n","Test error:  [[0.77824545]]\n","Iteration  99\n","Train error:  [[0.54095956]]\n","Test error:  [[0.77799282]]\n"]}],"source":["from scipy.sparse import csr_matrix\n","import copy\n","#initialize factor matrices\n","item_factors = {}\n","user_factors = {}\n","for i in range(n_prefs):\n","    user_factors[prefs.iloc[i,0]] = np.random.rand(n_factors,1) - 0.5\n","    item_factors[prefs.iloc[i,1]] = np.random.rand(n_factors,1) - 0.5\n","\n","X_train, X_test = train_test_split(prefs, test_size=0.1)\n","\n","train_users = X_train.iloc[:,0].unique()\n","train_items = X_train.iloc[:,1].unique()\n","R = csr_matrix((X_train.iloc[:,2], (X_train.iloc[:,0],X_train.iloc[:,1])))\n","\n","# Batch Gradient descent\n","alpha = 0.1\n","my_lambda = 0.1\n","n_iters = 100\n","\n","for t in range(n_iters):\n","    for u in train_users:\n","        I_u = X_train[X_train.userId==u].iloc[:,1]\n","        sum_total = 0\n","        for i in I_u:\n","            sum_total += (R[u,i] - np.dot(item_factors[i].T, user_factors[u])[0,0])*item_factors[i]\n","        sum_total = sum_total / I_u.size\n","        user_factors[u] = user_factors[u] + alpha*(sum_total - my_lambda*user_factors[u])\n","    for i in train_items:\n","        U_i = X_train[X_train.movieId==i].iloc[:,0]\n","        sum_total = 0\n","        for u in U_i:\n","            sum_total += (R[u,i] - np.dot(item_factors[i].T, user_factors[u])[0,0])*user_factors[u]\n","        sum_total = sum_total / U_i.size\n","        item_factors[i] = item_factors[i] + alpha*(sum_total - my_lambda*item_factors[i])\n","\n","    print(\"Iteration \", t)\n","    print(\"Train error: \", calc_error(X_train,user_factors,item_factors))\n","    print(\"Test error: \", calc_error(X_test,user_factors,item_factors))"]},{"cell_type":"markdown","metadata":{"id":"OcgyM8a9Sn9y"},"source":["### Question\n","\n","Suppose that user A appears in 200 rows in the user-item preferences dataset. In a single epoch how many updates will there be to the latent vector $p_u$ in stochastic GD vs. Batch GD?"]},{"cell_type":"markdown","metadata":{"id":"I8VFNtMINOhv"},"source":["## Optional Material"]},{"cell_type":"markdown","metadata":{"id":"nOwthAvMSn9y"},"source":["### Alternating Least Squares (ALS)\n","Since the datasets in this domain are really large, people always try to find ways to speed up the optimization processes. One popular algorithm is called ALS. Here the basic idea is that although the cost function is not convex, when either user factors or items factors are fixed then it becomes a convex function which can be directly solved. The algorithm alternates between updating user and item factors. ([Large-scale parallel collaborative filtering for the netflix prize](https://link.springer.com/chapter/10.1007/978-3-540-68880-8_32)).\n","\n","$$\n","\\frac{\\partial J(\\Theta)}{\\partial p_{ku}}=-\\sum_{i \\in I_u}2(r_{ui} - q^T_ip_u)q_{ki} + 2\\lambda p_{ku} = 0\n","$$\n","\n","$$\n","\\sum_{i \\in I_u} q_{ki}q^T_ip_u + \\lambda p_{ku} = \\sum_{i \\in I_u}q_{ki}r_{ui}\n","$$\n","\n","$$\n","\\sum_{i \\in I_u} q_{i}q^T_ip_u + \\lambda p_{u} = \\sum_{i \\in I_u}q_{i}r_{ui}\n","$$\n","\n","$$\n","(Q_{I_u}Q_{I_u}^T + \\lambda I) p_{u} = Q_{I_u}R^T(u,I_u)\n","$$\n","\n","$$\n","p_{u} = (Q_{I_u}Q_{I_u}^T + \\lambda I)^{-1}Q_{I_u}R^T(u,I_u)\n","$$\n","\n","where $I$ is the $f × f$ identity matrix. $Q_{I_u}$ denotes the sub-matrix of $Q$ where columns $j \\in I_u$ are selected, and $R^T(u,I_u)$ is the row vector where columns $j \\in I_u$ of the $u$-th row of $R$ are selected.\n","\n","Similarly for $q_i$ we have:\n","\n","$$\n","q_{i} = (P_{U_i}P_{U_i}^T + \\lambda I)^{-1}P_{U_i}R(U_i,i)\n","$$\n","\n","where $I$ is the $f × f$ identity matrix. $P_{U_i}$ denotes the sub-matrix of $P$ where columns $j \\in U_i$ are selected, and $R(U_i,i)$ is the column vector where columns $j \\in U_i$ of the $i$-th column of $R$ are selected.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mqRNL5UASn9z"},"outputs":[],"source":["#initialize factor matrices\n","n_factors = 5\n","\n","Q = pd.DataFrame(np.random.rand(n_factors,n_items)-0.5, columns=items)\n","P = pd.DataFrame(np.random.rand(n_factors,n_users)-0.5, columns=users)\n","\n","X_train, X_test = train_test_split(prefs, test_size=0.1)\n","\n","train_users = X_train.iloc[:,0].unique()\n","train_items = X_train.iloc[:,1].unique()\n","R = csr_matrix((X_train.iloc[:,2], (X_train.iloc[:,0],X_train.iloc[:,1])))\n","\n","alpha = 0.030\n","my_lambda = 0.1\n","n_iters = 100\n","\n","for t in range(n_iters):\n","    for u in train_users:\n","        I_u = X_train[X_train.userId==u].iloc[:,1]\n","        A = np.dot(Q[I_u],Q[I_u].T)+my_lambda*np.identity(n_factors)\n","        V = np.dot(Q[I_u],R[u,I_u].todense().T)\n","        P[u] = np.dot(np.linalg.inv(A),V)\n","    for i in train_items:\n","        U_i = X_train[X_train.movieId==i].iloc[:,0]\n","        A = np.dot(P[U_i],P[U_i].T)+my_lambda*np.identity(n_factors)\n","        V = np.dot(P[U_i],R[U_i,i].todense())\n","        Q[i] = np.dot(np.linalg.inv(A),V)\n","\n","    print(\"Iteration \", t)\n","    print(\"Train error: \", calc_error(X_train,P,Q))\n","    print(\"Test error: \", calc_error(X_test,P,Q))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KXgt5udkSn90"},"outputs":[],"source":["## The following has not yet finished\n","\n","class MF:\n","    \"\"\"\n","    prefs: matrix of prefences, column0=userid, column1=itemid, column2=pref, column3=timestamp\n","    \"\"\"\n","    def __init__(self, prefs, alpha=0.03, mylambda=0.1, n_factors = 10, n_iters = 50):\n","        self.alpha = alpha\n","        self.mylambda = mylambda\n","        self.n_iters = n_iters\n","        self.item_factors = {}\n","        self.user_factors = {}\n","        self.prefs = prefs\n","        # prefs is a matrix containing u, i, r values in each row. This is useful to shuffle and pass over\n","        # the data multiple times in an efficient way in the fit() method.\n","        for r in range(self.prefs.shape[0]):\n","            self.user_factors[self.prefs.iloc[r,0]] = np.random.rand(n_factors,1) - 0.5\n","            self.item_factors[self.prefs.iloc[r,1]] = np.random.rand(n_factors,1) - 0.5\n","        print(\"Finished initialization\")\n","\n","\n","    def calc_error(self, X):\n","        error = 0\n","        for i in range(X.shape[0]):\n","            u_idx = X.iloc[i,0]\n","            i_idx = X.iloc[i,1]\n","            error += np.abs(X.iloc[i,2] - np.dot(self.user_factors[u_idx].T, self.item_factors[i_idx]))\n","        return error/self.prefs.shape[0]\n","\n","    def fit(self, verbose=False, method=\"SGD\"):\n","        if (method == \"Random\"):\n","            error = 0\n","            for i in range(prefs.shape[0]):\n","                u_idx = prefs.iloc[i,0]\n","                i_idx = prefs.iloc[i,1]\n","                error += np.abs(prefs.iloc[i,2] - np.random.randint(1,6))\n","            return error/prefs.shape[0]\n","\n","        elif (method == \"SGD\"):\n","            if (verbose):\n","                print(\"Initial error: \", self.calc_error(prefs))\n","            for t in range(self.n_iters):\n","                self.prefs = shuffle(self.prefs)\n","                for r in range(self.prefs.shape[0]):\n","                    u = self.prefs.iloc[r,0]\n","                    i = self.prefs.iloc[r,1]\n","                    error = self.prefs.iloc[r,2] - np.dot(self.user_factors[u].T, self.item_factors[i])[0,0]\n","                    self.user_factors[u] = self.user_factors[u] + self.alpha*(error*self.item_factors[i] - self.mylambda*self.user_factors[u])\n","                    self.item_factors[i] = self.item_factors[i] + self.alpha*(error*self.user_factors[u] - self.mylambda*self.item_factors[i])\n","\n","                if (verbose):\n","                    print(\"Iteration: \", t)\n","                if (verbose):\n","                    print(\"Train error: \", self.calc_error(self.prefs))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nHyb23UT0QZ5"},"outputs":[],"source":["mf = MF(prefs)\n","mf.fit(verbose=True, method=\"SGD\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jk47h4VO05Wx"},"outputs":[],"source":["X_train, X_test = train_test_split(prefs, test_size=0.1)\n","mf = MF(X_train, n_iters=3)\n","mf.fit(verbose=True, method=\"Random\")\n","print(\"Test error: \", mf.calc_error(X_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kuBrKXzppkp4"},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"sklearn-env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}