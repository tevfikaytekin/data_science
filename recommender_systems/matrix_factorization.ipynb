{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/tevfikaytekin/data_science/blob/master/recommender_systems/matrix_factorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"dgs5IIoUSn9l"},"source":["# Matrix Factorization\n","(by Tevfik Aytekin)\n","\n","Matrix factorization is one of the state-of-the-art techniques used in recommender systems. Below you can find several different implementations.\n","\n","Over the years many variations of matrix factorization have been proposed. The following formulation is the standard one and constitutes the foundation of many others. It can be extended in various ways, see for example [Advances in Collaborative Filtering](https://link.springer.com/chapter/10.1007/978-1-4899-7637-6_3).\n","\n","\n","\n","Cost Function:\n","$$\n","J(\\Theta) =  \\sum_{u,i \\in K} (r_{ui} - (\\mu + b_u + b_i + q^T_ip_u))^2 + \\lambda(||q_i||^2+||p_u||^2 + ||b_u||^2 + ||b_i||^2)\n","$$\n","\n","where\n","\n","- $r_{ui}$ is the rating of user $u$ for item $i$.\n","- $K$ is the set of $(u,i)$ pairs for which $r_{ui}$ is known.\n","- $q_i$, $p_u$ are latent factor vectors for items and users, respectively.\n","- $\\lambda$ is the regularization parameter.\n","- $\\mu$: The overall average rating across all items and users. This accounts for the general rating scale.\n","- $b_u$: The bias of user $u$. This captures how much user $u$ tends to rate higher or lower than the average, independent of specific items.\n","- $b_i$: The bias of item $i$. This captures how much item $i$ tends to be rated higher or lower than the average, independent of specific users.\n","\n","To improve the accuracy of predictions, especially for sparse data, it's common to incorporate biases. These biases help capture systematic tendencies in ratings that are not explained by the latent factors.\n","\n","With these biases, the predicted rating for user $u$ on item $i$ is now $\\hat{r}_{ui} = \\mu + b_u + b_i + q^T_ip_u$.\n","\n","And the optimization objective:\n","\n","$$\n","\\min_{p*,q*,b_u*,b_i*} \\sum_{u,i \\in K} (r_{ui} - (\\mu + b_u + b_i + q^T_ip_u))^2 + \\lambda(||q_i||^2+||p_u||^2 + ||b_u||^2 + ||b_i||^2)\n","$$\n","\n","Typically the optimization done with gradient descent. To apply it we need to first find the partial derivative of the cost function with respect to latent variables and biases.\n","\n","We can find the partial derivatives as:\n","\n","$$\n","\\frac{\\partial J(\\Theta)}{\\partial p_{ku}}=-2\\sum_{i \\in I_u} e_{ui} q_{ki} + 2\\lambda p_{ku}\n","$$\n","$$\n","\\frac{\\partial J(\\Theta)}{\\partial q_{ki}}=-2\\sum_{u \\in U_i} e_{ui} p_{ku} + 2\\lambda q_{ki}\n","$$\n","$$\n","\\frac{\\partial J(\\Theta)}{\\partial b_u}=-2\\sum_{i \\in I_u} e_{ui} + 2\\lambda b_u\n","$$\n","$$\n","\\frac{\\partial J(\\Theta)}{\\partial b_i}=-2\\sum_{u \\in U_i} e_{ui} + 2\\lambda b_i\n","$$\n","\n","Let's define the error $e_{ui} = r_{ui} - (\\mu + b_u + b_i + q^T_ip_u)$.\n","\n","For **stochastic gradient descent** the update rules for a single training example $(u,i)$ are:\n","\n","\n","$$\n","p_u \\leftarrow p_u + \\alpha (e_{ui}q_{i} - \\lambda p_{u})\n","$$\n","$$\n","q_i \\leftarrow q_i + \\alpha (e_{ui}p_{u} - \\lambda q_{i})\n","$$\n","$$\n","b_u \\leftarrow b_u + \\alpha (e_{ui} - \\lambda b_u)\n","$$\n","$$\n","b_i \\leftarrow b_i + \\alpha (e_{ui} - \\lambda b_i)\n","$$\n","\n","For **batch gradient descent** the update rules are:\n","\n","$$\n","p_u \\leftarrow p_u + \\alpha (\\sum_{i \\in I_u}e_{ui}q_{i} - \\lambda p_{u})\n","$$\n","$$\n","q_i \\leftarrow q_i + \\alpha (\\sum_{u \\in U_i} e_{ui}p_{u} - \\lambda q_{i})\n","$$\n","$$\n","b_u \\leftarrow b_u + \\alpha (\\sum_{i \\in I_u}e_{ui} - \\lambda b_u)\n","$$\n","$$\n","b_i \\leftarrow b_i + \\alpha (\\sum_{u \\in U_i}e_{ui} - \\lambda b_i)\n","$$\n","\n","In the above equations $I_u$ is the set of items rated by user $u$ and $U_i$ is the set of users who rated item $i$.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"84apIe07Sn9q"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","from scipy.sparse import csr_matrix\n","import copy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uOefuRr5IKPO"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"xzo9HTNYSn9r"},"source":["# Movielens dataset\n","\n","We will use the smallest Movielens 100k Dataset which includes 100k preferences. A preference is a triple (user, item, rating). You can download this data set from\n","[https://grouplens.org/datasets/movielens/](https://grouplens.org/datasets/movielens/)\n","\n","Note the sparsity of the dataset which shows that most of the user/item matrix is empty. This is a typical property of the datasets in this domain."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JvZEZ2KFSn9r"},"outputs":[],"source":["#prefs = pd.read_csv(\"/content/drive/My Drive/datasets/ml-latest-small/ratings.csv\", sep=\",\")\n","prefs = pd.read_csv(\"ratings.csv\", sep=\",\")\n","\n","prefs.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KNUNaoQSSn9s","scrolled":true},"outputs":[],"source":["n_users = prefs.iloc[:,0].unique().size\n","n_items = prefs.iloc[:,1].unique().size\n","n_prefs = prefs.iloc[:,1].size\n","users = prefs.iloc[:,0].unique()\n","items = prefs.iloc[:,1].unique()\n","\n","print(\"Number of users:\",n_users)\n","print(\"Number of items:\",n_items)\n","print(\"Number of preferences:\",n_prefs)\n","print(\"Sparsity:\",n_prefs/(n_users*n_items))"]},{"cell_type":"markdown","metadata":{"id":"9A6dD4keSn9t"},"source":["### Error Function\n","\n","Error is calculated by predicting the rating of a user and an item in the test set using the factor representations of users and items."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R6xzCHN4Sn9t"},"outputs":[],"source":["def calc_error(X, u_factors, i_factors, mu, user_bias, item_bias):\n","    error = 0\n","    for i in range(X.shape[0]):\n","        u_idx = X.iloc[i,0]\n","        i_idx = X.iloc[i,1]\n","        prediction = mu + user_bias[u_idx] + item_bias[i_idx] + np.dot(u_factors[u_idx].T, i_factors[i_idx])\n","        error += np.abs(X.iloc[i,2] - prediction)\n","    return error/X.shape[0]\n"]},{"cell_type":"markdown","metadata":{"id":"AE8UpWc1Sn9u"},"source":["### Random Predictor Error\n","\n","**Exercise**: What is the expected error of a random predictor given that the actual ratings are uniformly distributed between 1 and 5?\n","\n","Below is a function for calculating this error experimentally."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NX4-hb8vSn9v"},"outputs":[],"source":["def random_predictor_error(X):\n","    error = 0\n","    for i in range(X.shape[0]):\n","        u_idx = X.iloc[i,0]\n","        i_idx = X.iloc[i,1]\n","        error += np.abs(X.iloc[i,2] - np.random.randint(1,6))\n","    return error/X.shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G04__7fiDCHz"},"outputs":[],"source":["print(\"Random predictor error: \", random_predictor_error(prefs))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bvgyC1VJSn9v"},"outputs":[],"source":["n_factors = 5\n","item_factors = {}\n","user_factors = {}\n","user_bias = {}\n","item_bias = {}\n","\n","mu = prefs.iloc[:,2].mean()\n","\n","for r in range(n_prefs):\n","    u_id = prefs.iloc[r,0]\n","    i_id = prefs.iloc[r,1]\n","\n","    user_bias[u_id] = 0.0\n","    item_bias[i_id] = 0.0\n","\n","    user_factors[u_id] = np.random.rand(n_factors,1) - 0.5\n","    item_factors[i_id] = np.random.rand(n_factors,1) - 0.5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qAVXvpFuSn9w"},"outputs":[],"source":["print(\"Initial error: \", calc_error(prefs, user_factors, item_factors, mu, user_bias, item_bias))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PaBjyPnJD3EU"},"outputs":[],"source":["item_factors[10]"]},{"cell_type":"markdown","metadata":{"id":"HhCmDB3TSn9x"},"source":["### Stochastic Gradient Descent\n","\n","Following is the stochastic gradient algorithm which is popularized by [Simon Funk](https://sifter.org/simon/journal/20061211.html)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_km686P-Sn9x"},"outputs":[],"source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","\n","# 1. Initialize\n","n_factors = 5\n","item_factors = {}\n","user_factors = {}\n","user_bias = {}\n","item_bias = {}\n","\n","# Calculate global mean\n","mu = prefs.iloc[:,2].mean()\n","\n","# Initialize factors and biases\n","for r in range(prefs.shape[0]):\n","    u_id = prefs.iloc[r,0]\n","    i_id = prefs.iloc[r,1]\n","\n","    user_bias[u_id] = 0.0\n","    item_bias[i_id] = 0.0\n","\n","    user_factors[u_id] = np.random.rand(n_factors,1) - 0.5\n","    item_factors[i_id] = np.random.rand(n_factors,1) - 0.5\n","\n","# 2. Split data\n","X_train, X_test = train_test_split(prefs, test_size=0.1)\n","\n","# 3. Hyperparameters\n","alpha = 0.03\n","my_lambda = 0.1\n","n_iters = 5\n","\n","# 4. Print initial error\n","print(\"Initial error: \", calc_error(X_train, user_factors, item_factors, mu, user_bias, item_bias))\n","\n","# 5. SGD Loop\n","for t in range(n_iters):\n","    X_train = shuffle(X_train)\n","    for r in range(X_train.shape[0]):\n","        u = X_train.iloc[r,0]\n","        i = X_train.iloc[r,1]\n","        rating = X_train.iloc[r,2]\n","\n","        # Prediction\n","        prediction = mu + user_bias[u] + item_bias[i] + np.dot(user_factors[u].T, item_factors[i])[0,0]\n","        error = rating - prediction\n","\n","        # Update biases\n","        user_bias[u] += alpha * (error - my_lambda * user_bias[u])\n","        item_bias[i] += alpha * (error - my_lambda * item_bias[i])\n","\n","        # Update latent factors\n","        # Store old values to use in update equations simultaneously\n","        u_f = user_factors[u].copy()\n","        i_f = item_factors[i].copy()\n","\n","        user_factors[u] += alpha * (error * i_f - my_lambda * u_f)\n","        item_factors[i] += alpha * (error * u_f - my_lambda * i_f)\n","\n","    print(\"Iteration \", t)\n","    print(\"Train error: \", calc_error(X_train, user_factors, item_factors, mu, user_bias, item_bias))\n","    print(\"Test error: \", calc_error(X_test, user_factors, item_factors, mu, user_bias, item_bias))"]},{"cell_type":"markdown","metadata":{"id":"NXo20Bw8etw8"},"source":["### How to make a prediction?\n","Once the user and item factors are learned you can make a prediction for any user and item pair."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"icHcr58-etw8"},"outputs":[],"source":["item_factors[10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AiSJslsTetw9"},"outputs":[],"source":["user_factors[100]"]},{"cell_type":"code","source":["user_bias[100]"],"metadata":{"id":"etuXSJG9_7wi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_pred(u_idx, i_idx):\n","  return mu + user_bias[u_idx] + item_bias[i_idx] + np.dot(user_factors[u_idx].T, item_factors[i_idx])"],"metadata":{"id":"xLbVKhIvZ-6X"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z7QhXG-fetw-"},"outputs":[],"source":["make_pred(10,50)"]},{"cell_type":"markdown","metadata":{"id":"dgGw4j4GSn9y"},"source":["### Batch Gradient Descent\n","If you run the code below you will see that both training and test errors decrease very slowly. Eventually there will be convergence but compared to stochastic version it will be very slow. It is a good example to show the speed advantage of stochastic gradient descent."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MdUJbtKBSn9y"},"outputs":[],"source":["from scipy.sparse import csr_matrix\n","\n","# 1. Initialize\n","n_factors = 5\n","item_factors = {}\n","user_factors = {}\n","user_bias = {}\n","item_bias = {}\n","\n","# Calculate global mean\n","mu = prefs.iloc[:,2].mean()\n","\n","# Initialize factors and biases\n","for r in range(prefs.shape[0]):\n","    u_id = prefs.iloc[r,0]\n","    i_id = prefs.iloc[r,1]\n","\n","    user_bias[u_id] = 0.0\n","    item_bias[i_id] = 0.0\n","\n","    user_factors[u_id] = np.random.rand(n_factors,1) - 0.5\n","    item_factors[i_id] = np.random.rand(n_factors,1) - 0.5\n","\n","# 2. Split data\n","X_train, X_test = train_test_split(prefs, test_size=0.1)\n","\n","train_users = X_train.iloc[:,0].unique()\n","train_items = X_train.iloc[:,1].unique()\n","\n","# Create sparse matrices for efficient lookups\n","# R rows correspond to userIds, cols to movieIds\n","# Use max dimensions to accommodate all IDs\n","R = csr_matrix((X_train.iloc[:,2], (X_train.iloc[:,0], X_train.iloc[:,1])))\n","R_csc = R.tocsc()\n","\n","# 3. Hyperparameters\n","alpha = 0.1\n","my_lambda = 0.1\n","n_iters = 30 # Reduced iterations for demonstration speed, original was 100\n","\n","print(\"Initial error: \", calc_error(X_train, user_factors, item_factors, mu, user_bias, item_bias))\n","\n","# 4. BGD Loop\n","for t in range(n_iters):\n","    # Update User Factors and Biases\n","    for u in train_users:\n","        # Get items rated by user u\n","        # R[u] returns a sparse row vector. .indices gives the column indices (itemIds)\n","        # .data gives the ratings\n","        # Note: R is 0-indexed based on the IDs provided.\n","        # Since IDs in movielens start at 1, row 0 is empty.\n","\n","        # Efficiently get items and ratings\n","        u_row = R[u]\n","        I_u_indices = u_row.indices\n","        if len(I_u_indices) == 0: continue\n","\n","        # Pre-calculate errors for this user\n","        # We need to loop because item_factors is a dict\n","        # Vectorizing with dicts is hard without converting to full matrices\n","\n","        grad_p_u = np.zeros((n_factors, 1))\n","        grad_b_u = 0\n","\n","        for i in I_u_indices:\n","            rating = R[u, i] # This access is fast enough or use u_row.data\n","            prediction = mu + user_bias[u] + item_bias[i] + np.dot(user_factors[u].T, item_factors[i])[0,0]\n","            error = rating - prediction\n","\n","            grad_p_u += (error * item_factors[i])\n","            grad_b_u += error\n","\n","        # Average gradients\n","        grad_p_u /= len(I_u_indices)\n","        grad_b_u /= len(I_u_indices)\n","\n","        # Update with regularization\n","        user_factors[u] += alpha * (grad_p_u - my_lambda * user_factors[u])\n","        user_bias[u] += alpha * (grad_b_u - my_lambda * user_bias[u])\n","\n","    # Update Item Factors and Biases\n","    for i in train_items:\n","        # Get users who rated item i\n","        i_col = R_csc[:, i]\n","        U_i_indices = i_col.indices\n","        if len(U_i_indices) == 0: continue\n","\n","        grad_q_i = np.zeros((n_factors, 1))\n","        grad_b_i = 0\n","\n","        for u in U_i_indices:\n","            rating = R[u, i]\n","            prediction = mu + user_bias[u] + item_bias[i] + np.dot(user_factors[u].T, item_factors[i])[0,0]\n","            error = rating - prediction\n","\n","            grad_q_i += (error * user_factors[u])\n","            grad_b_i += error\n","\n","        # Average gradients\n","        grad_q_i /= len(U_i_indices)\n","        grad_b_i /= len(U_i_indices)\n","\n","        # Update with regularization\n","        item_factors[i] += alpha * (grad_q_i - my_lambda * item_factors[i])\n","        item_bias[i] += alpha * (grad_b_i - my_lambda * item_bias[i])\n","\n","    print(\"Iteration \", t)\n","    print(\"Train error: \", calc_error(X_train, user_factors, item_factors, mu, user_bias, item_bias))\n","    print(\"Test error: \", calc_error(X_test, user_factors, item_factors, mu, user_bias, item_bias))"]},{"cell_type":"markdown","source":["## Self-Test Questions and Answers\n","\n","Here are some questions to test your understanding of the material covered in this notebook. Try to answer them before looking at the provided answers.\n","\n","**1. SGD vs. Batch Gradient Descent**\n","\n","*Question:* In the context of Matrix Factorization, what is the main difference between Stochastic Gradient Descent (SGD) and Batch Gradient Descent (BGD) regarding how often the parameters are updated?\n","\n","*Answer:* In SGD, parameters ($p_u, q_i, b_u, b_i$) are updated after processing each individual rating (preference). In BGD, parameters are updated only after calculating the gradient over all relevant ratings (e.g., all items rated by user $u$ or all users who rated item $i$). This generally makes SGD converge faster for large, sparse datasets.\n","\n","---\n","\n","**2. Regularization**\n","\n","*Question:* What is the purpose of the regularization parameter $\\lambda$ in the cost function?\n","\n","*Answer:* The regularization parameter $\\lambda$ prevents overfitting by penalizing large values in the latent factor vectors and biases. It adds a term to the cost function proportional to the magnitude (squared norm) of the parameters. This encourages the model to learn simpler patterns and generalize better to unseen data.\n","\n","---\n","\n","**3. User and Item Biases**\n","\n","*Question:* Why is it important to include bias terms $b_u$ (user bias) and $b_i$ (item bias) in the model?\n","\n","*Answer:* Bias terms capture effects that are independent of specific user-item interactions. $b_u$ accounts for a user's tendency to rate everything high or low (e.g., a critical user vs. a generous one), and $b_i$ accounts for an item's general popularity or quality (e.g., a blockbuster movie vs. a flop). Modeling these explicitly allows the latent factors to focus on true interaction preferences.\n","\n","---\n","\n","**4. Calculation Exercise**\n","\n","*Question:* Suppose we have the following learned parameters:\n","- Global mean $\\mu = 3.5$\n","- User bias $b_u = 0.5$\n","- Item bias $b_i = -0.2$\n","- User latent vector $p_u = [0.4, 0.1]$\n","- Item latent vector $q_i = [1.0, -2.0]$\n","\n","What is the predicted rating $\\hat{r}_{ui}$?\n","\n","*Answer:*\n","The prediction formula is: $\\hat{r}_{ui} = \\mu + b_u + b_i + p_u \\cdot q_i$\n","\n","Dot product $p_u \\cdot q_i = (0.4 \\times 1.0) + (0.1 \\times -2.0) = 0.4 - 0.2 = 0.2$\n","\n","$\\hat{r}_{ui} = 3.5 + 0.5 - 0.2 + 0.2 = 4.0$\n","\n","---\n","\n","**5. Training Calculation Exercise (Stochastic Gradient Descent Update)**\n","\n","*Question:* Suppose you are performing Stochastic Gradient Descent (SGD) for Matrix Factorization. You have the following parameters and hyperparameters at a specific step for user $u$ and item $i$:\n","- Global mean $\\mu = 3.5$\n","- Current User bias $b_u = 0.5$\n","- Current Item bias $b_i = -0.2$\n","- Current User latent vector $p_u = [0.4, 0.1]$\n","- Current Item latent vector $q_i = [1.0, -2.0]$\n","- Actual rating $r_{ui} = 4.5$\n","- Learning rate $\\alpha = 0.01$\n","- Regularization parameter $\\lambda = 0.1$\n","\n","What is the updated value of the user bias $b_u$ after one SGD step?\n","\n","*Answer:*\n","The prediction formula is: $\\hat{r}_{ui} = \\mu + b_u + b_i + p_u \\cdot q_i$\n","\n","1.  **Calculate the dot product $p_u \\cdot q_i$:**\n","    $p_u \\cdot q_i = (0.4 \\times 1.0) + (0.1 \\times -2.0) = 0.4 - 0.2 = 0.2$\n","\n","2.  **Calculate the predicted rating $\\hat{r}_{ui}$:**\n","    $\\hat{r}_{ui} = 3.5 + 0.5 + (-0.2) + 0.2 = 4.0$\n","\n","3.  **Calculate the error $e_{ui}$:**\n","    $e_{ui} = r_{ui} - \\hat{r}_{ui} = 4.5 - 4.0 = 0.5$\n","\n","4.  **Apply the SGD update rule for $b_u$:**\n","    $b_u \\leftarrow b_u + \\alpha (e_{ui} - \\lambda b_u)$\n","\n","    $b_u \\leftarrow 0.5 + 0.01 (0.5 - 0.1 \\times 0.5)$\n","    \n","    $b_u \\leftarrow 0.5 + 0.01 (0.5 - 0.05)$\n","    \n","    $b_u \\leftarrow 0.5 + 0.01 (0.45)$\n","    \n","    $b_u \\leftarrow 0.5 + 0.0045$\n","    \n","    $b_u = 0.5045$\n","\n","The updated user bias $b_u$ is $0.5045$.\n","\n","---\n","\n","**6. SGD vs. Batch GD Update Count**\n","\n","*Question:* Suppose that user A appears in 200 rows in the user-item preferences dataset. In a single epoch, how many updates will there be to the latent vector $p_u$ in Stochastic Gradient Descent (SGD) versus Batch Gradient Descent (BGD)?\n","\n","*Answer:*\n","*   **Stochastic Gradient Descent (SGD):** In SGD, parameters are updated for each individual training example. If user A appears in 200 rows, it means user A has 200 ratings. Therefore, in a single epoch, the latent vector $p_u$ for user A will be updated **200 times** (once for each rating involving user A).\n","\n","*   **Batch Gradient Descent (BGD):** In BGD, parameters are updated only once per epoch after considering all relevant training examples. For user A, all 200 ratings involving user A will be used to calculate the gradient, but the latent vector $p_u$ will be updated only **1 time** at the end of the epoch."],"metadata":{"id":"tTtZ0lQkUivj"}},{"cell_type":"code","source":[],"metadata":{"id":"g2mT2VXSUcpG"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"sklearn-env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}